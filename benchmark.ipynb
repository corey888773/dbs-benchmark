{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ae7c2b-1b56-4aa9-a2bf-d5c1748d744d",
   "metadata": {},
   "source": [
    "# Scenariusze testowe dla porównania wydajności baz danych\n",
    "\n",
    "### 1. Operacja CREATE\n",
    "\n",
    "- Dodanie nowego nauczyciela\n",
    "- Utworzenie nowej klasy\n",
    "- Dodanie nowego przedmiotu\n",
    "- Zarejestrowanie nowego ucznia\n",
    "- Przypisanie ucznia do klasy (**Dodano: Zapisanie ucznia do klasy (enrolment)**)\n",
    "- Utworzenie harmonogramu zajęć\n",
    "- Wystawienie oceny\n",
    "\n",
    "### 2. Operacja READ\n",
    "\n",
    "Pobranie kompleksowego raportu zawierającego:\n",
    "- Dane osobowe ucznia\n",
    "- Informacje o klasie (**Dodano: Informacje o zapisach do klas**)\n",
    "- Dane nauczyciela prowadzącego\n",
    "- Listę ocen z opisami przedmiotów\n",
    "- Szczegółowy harmonogram zajęć\n",
    "\n",
    "### 3. Operacja UPDATE\n",
    "\n",
    "- Aktualizacja danych ucznia\n",
    "- Zmiana przypisania do klasy (**Dodano: Aktualizacja zapisu do klasy**)\n",
    "- Modyfikacja nazwy klasy\n",
    "- Aktualizacja danych nauczyciela\n",
    "- Zmiana oceny\n",
    "- Aktualizacja opisu przedmiotu\n",
    "- Modyfikacja harmonogramu zajęć\n",
    "\n",
    "### 4. Operacja DELETE\n",
    "\n",
    "- Usunięcie ocen ucznia\n",
    "- Wypisanie ucznia z klasy (**Dodano: Usunięcie zapisu do klasy**)\n",
    "- Usunięcie harmonogramu zajęć\n",
    "- Usunięcie klasy\n",
    "- Opcjonalne usunięcie przedmiotów\n",
    "- Opcjonalne usunięcie nauczyciela\n",
    "- Usunięcie rekordu ucznia\n",
    "\n",
    "## Ilość rekordów do testów\n",
    "\n",
    "Testy będą przeprowadzane dla następujących ilości rekordów:\n",
    "\n",
    "1. 10,000 rekordów\n",
    "2. 100,000 rekordów\n",
    "3. 1,000,000 rekordów\n",
    "4. 10,000,000 rekordów\n",
    "\n",
    "## Metryki wydajnościowe\n",
    "\n",
    "Dla każdego scenariusza i ilości rekordów będziemy mierzyć:\n",
    "\n",
    "1. Czas wykonania całego scenariusza\n",
    "2. Średni czas pojedynczych operacji\n",
    "3. Liczbę operacji na sekundę (throughput)\n",
    "4. Zużycie zasobów systemowych (CPU, RAM, I/O dysku)\n",
    "\n",
    "# Narzędzia i technologie testowe\n",
    "\n",
    "### Wbudowane instrumenty bazodanowe\n",
    "\n",
    "Każdy system oferuje specjalizowane narzędzia diagnostyczne:\n",
    "\n",
    "| System | Narzędzie | Funkcjonalności |\n",
    "| :-- | :-- | :-- |\n",
    "| PostgreSQL | pgBench | Testy TPC-B, własne skrypty SQL |\n",
    "| MariaDB | sysbench | Testy OLTP, skalowanie pionowe |\n",
    "| MongoDB | mongoperf | Operacje na dokumentach JSON |\n",
    "| Cassandra | cassandra-stress | Testy dystrybucji danych |\n",
    "| Redis | redis-benchmark | Pomiar opóźnień operacji klucz-wartość |\n",
    "\n",
    "Wykorzystanie natywnych narzędzi pozwala na precyzyjne badanie specyficznych mechanizmów storage engine.\n",
    "\n",
    "### Automatyzacja w Pythonie\n",
    "\n",
    "Kluczowe biblioteki wspierające testy:\n",
    "\n",
    "- **SQLAlchemy** dla baz relacyjnych\n",
    "- **PyMongo** dla MongoDB\n",
    "- **Cassandra-driver** dla Cassandra\n",
    "- **redis-py** dla Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec37216-90ff-435c-9669-67af3f25c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import psycopg2\n",
    "import psycopg2.errors\n",
    "from pymongo import MongoClient\n",
    "from cassandra.cluster import Cluster\n",
    "import redis\n",
    "import mysql.connector\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Load database configuration\n",
    "print(\"Setting up database connections...\")\n",
    "with open('docker-compose.yml', 'r') as file:\n",
    "    docker_config = yaml.safe_load(file)\n",
    "\n",
    "# PostgreSQL connection\n",
    "postgres_config = docker_config['services']['postgresql']\n",
    "postgres_client = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    database=postgres_config['environment']['POSTGRES_DB'],\n",
    "    user=postgres_config['environment']['POSTGRES_USER'],\n",
    "    password=postgres_config['environment']['POSTGRES_PASSWORD'],\n",
    "    port=postgres_config['ports'][0].split(':')[0]\n",
    ")\n",
    "\n",
    "# MariaDB connection\n",
    "mariadb_config = docker_config['services']['mariadb']\n",
    "mariadb_client = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    database=mariadb_config['environment']['MYSQL_DATABASE'],\n",
    "    user=mariadb_config['environment']['MYSQL_USER'],\n",
    "    password=mariadb_config['environment']['MYSQL_PASSWORD'],\n",
    "    port=mariadb_config['ports'][0].split(':')[0],\n",
    "    allow_local_infile=True\n",
    ")\n",
    "\n",
    "# MongoDB connection\n",
    "mongo_config = docker_config['services']['mongodb']\n",
    "mongo_client = MongoClient(\n",
    "    host='localhost',\n",
    "    port=int(mongo_config['ports'][0].split(':')[0])\n",
    ")\n",
    "\n",
    "# Cassandra connection\n",
    "cassandra_config = docker_config['services']['cassandra']\n",
    "cassandra_client = Cluster(['localhost'], port=cassandra_config['ports'][0].split(':')[0])\n",
    "cassandra_session = cassandra_client.connect()\n",
    "\n",
    "# Redis connection\n",
    "redis_config = docker_config['services']['redis']\n",
    "redis_client = redis.Redis(\n",
    "    host='localhost',\n",
    "    port=int(redis_config['ports'][0].split(':')[0])\n",
    ")\n",
    "\n",
    "# Test connections\n",
    "try:\n",
    "    postgres_client.cursor().execute(\"SELECT 1\")\n",
    "    print(\"INFO: PostgreSQL connection successful\")\n",
    "    \n",
    "    mariadb_client.cursor(buffered=True).execute(\"SELECT 1\")\n",
    "    print(\"INFO: MariaDB connection successful\")\n",
    "    \n",
    "    cassandra_session.execute(\"SELECT release_version FROM system.local\")\n",
    "    print(\"INFO: Cassandra connection successful\")\n",
    "    \n",
    "    mongo_client.admin.command('ping')\n",
    "    print(\"INFO: MongoDB connection successful\")\n",
    "    \n",
    "    redis_client.ping()\n",
    "    print(\"INFO: Redis connection successful\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Connection test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7675e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_END = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd51d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation functions\n",
    "sys.path.append(str(Path.cwd()))\n",
    "from generator import generate_school_data\n",
    "\n",
    "def generate_files(output_dir='./data', scale=1000, batch_size=10000, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate synthetic school data files for benchmarking.\n",
    "    \"\"\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"INFO: Generating data with scale {scale} and batch size {batch_size}...\")\n",
    "\n",
    "    result = generate_school_data(\n",
    "        output_dir=output_dir,\n",
    "        scale=scale,\n",
    "        batch_size=batch_size,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    print(f\"INFO: Generated {len(result['students'])} students, {len(result['teachers'])} teachers, \" + \n",
    "        f\"{len(result['classes'])} classes, {len(result['subjects'])} subjects\")\n",
    "    print(\"=\"*50)\n",
    "    return result\n",
    "\n",
    "# Generate test data sets\n",
    "scale_100_dir = './data/scale_100'\n",
    "\n",
    "generate_files(output_dir=scale_100_dir, scale=100, batch_size=5000)\n",
    "CELL_END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2dd2d0",
   "metadata": {},
   "source": [
    "# PostgreSQL Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL Methods\n",
    "\n",
    "def initialize_postgres_schema(conn, schema_sql):\n",
    "    \"\"\"\n",
    "    Initializes the PostgreSQL database schema using the provided SQL script.\n",
    "    \"\"\"\n",
    "    if not schema_sql:\n",
    "        print(\"ERROR: Schema SQL content is empty.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(schema_sql)\n",
    "        conn.commit()\n",
    "        print(\"INFO: PostgreSQL schema initialized.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"ERROR: Error initializing PostgreSQL schema: {e}\")\n",
    "\n",
    "def verify_postgres_tables(conn, expected_tables):\n",
    "    \"\"\"\n",
    "    Verifies if the expected tables exist in PostgreSQL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT table_name\n",
    "                FROM information_schema.tables\n",
    "                WHERE table_schema = 'public' AND table_name = ANY(%s);\n",
    "            \"\"\", (expected_tables,))\n",
    "            existing_tables = {row[0] for row in cur.fetchall()}\n",
    "\n",
    "        missing_tables = set(expected_tables) - existing_tables\n",
    "        if not missing_tables:\n",
    "            print(f\"INFO: All PostgreSQL tables exist: {', '.join(expected_tables)}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"WARNING: Missing PostgreSQL tables: {', '.join(missing_tables)}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Error verifying PostgreSQL tables: {e}\")\n",
    "        return False\n",
    "\n",
    "def insert_postgres_table_from_csv(conn, table_name, csv_file) -> tuple[float, float, float]:\n",
    "    # Inserts data from a CSV file into a PostgreSQL table using INSERT.\n",
    "    # Does not fail on duplicate key errors.\n",
    "    # Assumes the table already exists and has the same structure as the CSV file.\n",
    "    \n",
    "    operation_start_time = time.time() # Initialize start_time\n",
    "    file_opened_start_time = 0 # Initialize file_opened_start_time\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            with open(csv_file, 'r') as f:\n",
    "                next(f)  # Skip header\n",
    "                file_opened_start_time = time.time() # Initialize start_time when file is opened\n",
    "                for line in f:\n",
    "                    values = line.strip().split(',')\n",
    "                    insert_sql = f\"INSERT INTO {table_name} VALUES ({', '.join(['%s'] * len(values))})\"\n",
    "                    try:\n",
    "                        cur.execute(insert_sql, values)\n",
    "                    except psycopg2.errors.UniqueViolation:\n",
    "                        # Ignore duplicate key errors\n",
    "                        conn.rollback()\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        print(f\"ERROR: Error inserting into {table_name}: {e}\")\n",
    "                        conn.rollback()\n",
    "                        break\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"ERROR: Error inserting data from {csv_file} into {table_name}: {e}\")\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def copy_postgres_table_from_csv(conn, table_name, csv_file) -> tuple[float, float, float]:\n",
    "    # Inserts data from a CSV file into a PostgreSQL table using COPY.\n",
    "    # Does not fail on duplicate key errors.\n",
    "    # Assumes the table already exists and has the same structure as the CSV file.\n",
    "    operation_start_time = time.time() # Initialize start_time\n",
    "    file_opened_start_time = 0 # Initialize file_opened_start_time\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            copy_sql = f\"COPY {table_name} FROM STDIN WITH (FORMAT CSV, HEADER)\"\n",
    "            with open(csv_file, 'r') as f:\n",
    "                file_opened_start_time = time.time() # Initialize start_time when file is opened\n",
    "                cur.copy_expert(sql=copy_sql, file=f)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"ERROR: Error inserting data from {csv_file} into {table_name}: {e}\")\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def copy_postgres_enrollments_from_csv(conn, csv_file):\n",
    "    # This function is a specialized version for the enrollments table, because it has a composite primary key.\n",
    "    # Inserts data from a CSV file into the enrollments table using COPY.\n",
    "    # Does not fail on duplicate key errors.\n",
    "    # Uses a temporary table to handle duplicates.\n",
    "\n",
    "    operation_start_time = time.time() # Initialize start_time\n",
    "    file_opened_start_time = 0 # Initialize file_opened_start_time\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # Create a temporary table for the COPY operation\n",
    "            temp_table_name = \"temp_enrollments\"\n",
    "            cur.execute(f\"\"\"\n",
    "                CREATE TEMP TABLE {temp_table_name} (\n",
    "                    student_id INT,\n",
    "                    class_id INT,\n",
    "                    enrolled_at TIMESTAMP\n",
    "                ) ON COMMIT DROP;\n",
    "            \"\"\")\n",
    "            copy_sql = f\"COPY {temp_table_name} FROM STDIN WITH (FORMAT CSV, HEADER)\"\n",
    "            with open(csv_file, 'r') as f:\n",
    "                file_opened_start_time = time.time()\n",
    "                cur.copy_expert(sql=copy_sql, file=f)\n",
    "\n",
    "            # Insert into the main table, ignoring duplicates\n",
    "            insert_sql = f\"\"\"\n",
    "                INSERT INTO enrollments (student_id, class_id, enrolled_at)\n",
    "                SELECT student_id, class_id, enrolled_at FROM {temp_table_name}\n",
    "                ON CONFLICT (student_id, class_id) DO NOTHING;\n",
    "            \"\"\"\n",
    "            cur.execute(insert_sql)\n",
    "            conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"ERROR: Error inserting data from {csv_file} into enrollments: {e}\")\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def load_postgres_data(conn, data_dir):\n",
    "    \"\"\"\n",
    "    Loads data from CSV files into PostgreSQL tables.\n",
    "    \"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    table_csv_map = {\n",
    "        'teachers': 'teachers.csv',\n",
    "        'subjects': 'subjects.csv',\n",
    "        'classes': 'classes.csv',\n",
    "        'students': 'students.csv',\n",
    "        'grades': 'grades.csv',\n",
    "        'schedules': 'schedules.csv',\n",
    "        # 'enrollments': 'enrollments.csv' # Handled separately\n",
    "    }\n",
    "    for table_name, csv_file in table_csv_map.items():\n",
    "        op_time, f_op_time, end_time = copy_postgres_table_from_csv(conn, table_name, data_path / csv_file)\n",
    "        print(f\"INFO: Inserted {table_name} in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "\n",
    "    # Handle enrollments separately due to composite primary key\n",
    "    op_time, f_op_time, end_time = copy_postgres_enrollments_from_csv(conn, data_path / 'enrollments.csv')\n",
    "    print(f\"INFO: Inserted enrollments in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "\n",
    "def verify_postgres_counts(conn, tables):\n",
    "    \"\"\"\n",
    "    Counts rows in PostgreSQL tables.\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    max_len = max(len(t) for t in tables) if tables else 0\n",
    "    print(f\"INFO: Counting rows in PostgreSQL tables\")\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            for table_name in tables:\n",
    "                try:\n",
    "                    cur.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "                    count = cur.fetchone()[0]\n",
    "                    counts[table_name] = count\n",
    "                except Exception as count_error:\n",
    "                    print(f\"ERROR: {count_error}\")\n",
    "                    counts[table_name] = 'Error'\n",
    "\n",
    "        print(\"--- PostgreSQL Table Row Counts ---\")\n",
    "        for table, count in counts.items():\n",
    "            print(f\"{table:<{max_len}} : {count}\")\n",
    "        print(\"-----------------------------------\")\n",
    "        return counts\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d53c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL Operations Execution\n",
    "\n",
    "# Schema initialization\n",
    "with open('schemas/postgres_schema.sql', 'r') as f:\n",
    "    sql_schema = f.read()\n",
    "\n",
    "initialize_postgres_schema(postgres_client, sql_schema)\n",
    "\n",
    "# Table verification \n",
    "required_tables = ['teachers', 'subjects', 'classes', 'students', 'enrollments', 'grades', 'schedules']\n",
    "verify_postgres_tables(postgres_client, required_tables)\n",
    "\n",
    "# Data loading\n",
    "load_postgres_data(postgres_client, scale_100_dir)\n",
    "\n",
    "# Count verification\n",
    "verify_postgres_counts(postgres_client, required_tables)\n",
    "CELL_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721535d9",
   "metadata": {},
   "source": [
    "# MariaDB Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MariaDB Methods\n",
    "\n",
    "def initialize_mariadb_schema(conn, schema_sql):\n",
    "    \"\"\"\n",
    "    Initializes the MariaDB database schema using the provided SQL script.\n",
    "    \"\"\"\n",
    "    if not schema_sql:\n",
    "        print(\"ERROR: Schema SQL content is empty.\")\n",
    "        return\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            for statement in schema_sql.split(';'):\n",
    "                stmt = statement.strip()\n",
    "                if stmt:\n",
    "                    cur.execute(stmt)\n",
    "        conn.commit()\n",
    "        print(\"INFO: MariaDB schema initialized.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"ERROR: Error initializing MariaDB schema: {e}\")\n",
    "\n",
    "def verify_mariadb_tables(conn, expected_tables):\n",
    "    \"\"\"\n",
    "    Verifies if the expected tables exist in MariaDB.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            format_strings = ','.join(['%s'] * len(expected_tables))\n",
    "            cur.execute(f\"\"\"\n",
    "                SELECT table_name\n",
    "                FROM information_schema.tables\n",
    "                WHERE table_schema = DATABASE() AND table_name IN ({format_strings});\n",
    "            \"\"\", tuple(expected_tables))\n",
    "            existing_tables = {row[0] for row in cur.fetchall()}\n",
    "\n",
    "        missing_tables = set(expected_tables) - existing_tables\n",
    "        if not missing_tables:\n",
    "            print(f\"INFO: All MariaDB tables exist: {', '.join(expected_tables)}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"WARNING: Missing MariaDB tables: {', '.join(missing_tables)}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Error verifying MariaDB tables: {e}\")\n",
    "        return False\n",
    "\n",
    "def insert_mariadb_table_from_csv(conn, table_name, csv_file) -> tuple[float, float, float]:\n",
    "    \"\"\"Inserts data from a CSV file into a MariaDB table by reading the header for columns.\"\"\"\n",
    "    operation_start_time = time.time()\n",
    "    file_opened_start_time = 0\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            with open(csv_file, 'r') as f:\n",
    "                # read header for column names\n",
    "                header = next(f).strip().split(',')\n",
    "                cols = header\n",
    "                placeholders = ','.join(['%s'] * len(cols))\n",
    "                insert_sql = f\"INSERT INTO {table_name} ({','.join(cols)}) VALUES ({placeholders})\"\n",
    "                file_opened_start_time = time.time()\n",
    "                for line in f:\n",
    "                    values = line.strip().split(',')\n",
    "                    # ensure values length matches columns\n",
    "                    if len(values) != len(cols):\n",
    "                        if len(values) > len(cols):\n",
    "                            values = values[:len(cols)]\n",
    "                        else:\n",
    "                            print(f\"WARNING: Skipping {table_name} row with {len(values)} values (expected {len(cols)}, values: {values})\")\n",
    "                            continue\n",
    "                    try:\n",
    "                        cur.execute(insert_sql, values)\n",
    "                    except mysql.connector.errors.IntegrityError:\n",
    "                        conn.rollback()\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        print(f\"ERROR: Error inserting into {table_name}: {e}\")\n",
    "                        conn.rollback()\n",
    "                        break\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"ERROR: Error inserting data from {csv_file} into {table_name}: {e}\")\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "\n",
    "def copy_mariadb_table_from_csv(conn, table_name, csv_file) -> tuple[float, float, float]:\n",
    "    # Inserts data from a CSV file into a MariaDB table using COPY.\n",
    "    # Does not fail on duplicate key errors.\n",
    "    # Assumes the table already exists and has the same structure as the CSV file.\n",
    "    \n",
    "    operation_start_time = time.time() # Initialize start_time\n",
    "    file_opened_start_time = 0 # Initialize file_opened_start_time\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            copy_sql = f\"\"\"\n",
    "            LOAD DATA LOCAL INFILE '{csv_file}'\n",
    "            INTO TABLE {table_name}\n",
    "            FIELDS TERMINATED BY ','\n",
    "            OPTIONALLY ENCLOSED BY '\"'\n",
    "            LINES TERMINATED BY '\\n'\n",
    "            IGNORE 1 LINES;\n",
    "            \"\"\"\n",
    "            with open(csv_file, 'r') as f:\n",
    "                file_opened_start_time = time.time() # Initialize start_time when file is opened\n",
    "                cur.execute(copy_sql)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"ERROR: Error inserting data from {csv_file} into {table_name}: {e}\")\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def copy_mariadb_enrollments_from_csv(conn, csv_file):\n",
    "    # This function is a specialized version for the enrollments table, because it has a composite primary key.\n",
    "    # Inserts data from a CSV file into the enrollments table using COPY.\n",
    "    # Does not fail on duplicate key errors.\n",
    "    # Uses a temporary table to handle duplicates.\n",
    "\n",
    "    operation_start_time = time.time() # Initialize start_time\n",
    "    file_opened_start_time = 0 # Initialize file_opened_start_time\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # Handle enrollments with INSERT IGNORE to skip duplicates\n",
    "            print(f\"INFO: Loading enrollments with duplicate handling...\")\n",
    "            with open(csv_file, 'r') as f:\n",
    "                next(f)  # skip header\n",
    "                for line in f:\n",
    "                    student_id, class_id, enrolled_at = line.strip().split(',')\n",
    "                    cur.execute(\n",
    "                        \"\"\"\n",
    "                        INSERT IGNORE INTO enrollments (student_id, class_id, enrolled_at)\n",
    "                        VALUES (%s, %s, %s)\n",
    "                        \"\"\",\n",
    "                        (student_id, class_id, enrolled_at)\n",
    "                    )\n",
    "            conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"ERROR: Error inserting data from {csv_file} into enrollments: {e}\")\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def load_mariadb_data(conn, data_dir):\n",
    "    table_csv_map = {\n",
    "    'teachers': 'teachers.csv',\n",
    "    'subjects': 'subjects.csv',\n",
    "    'classes': 'classes.csv',\n",
    "    'students': 'students.csv',\n",
    "    'grades': 'grades.csv',\n",
    "    'schedules': 'schedules.csv',\n",
    "    # 'enrollments': 'enrollments.csv' Handled separately\n",
    "    }\n",
    "    data_path = Path(data_dir)\n",
    "    for table_name, csv_file in table_csv_map.items():\n",
    "        op_time, f_op_time, end_time = insert_mariadb_table_from_csv(conn, table_name, data_path / csv_file)\n",
    "        print(f\"INFO: Inserted {table_name} in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "\n",
    "    # Handle enrollments separately due to composite primary key\n",
    "    op_time, f_op_time, end_time = copy_mariadb_enrollments_from_csv(conn, data_path / 'enrollments.csv')\n",
    "    print(f\"INFO: Inserted enrollments in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "\n",
    "def verify_mariadb_counts(conn, tables):\n",
    "    \"\"\"\n",
    "    Counts rows in MariaDB tables.\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    max_len = max(len(t) for t in tables) if tables else 0\n",
    "    print(f\"INFO: Counting rows in MariaDB tables\")\n",
    "    \n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            for table_name in tables:\n",
    "                try:\n",
    "                    cur.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "                    count = cur.fetchone()[0]\n",
    "                    counts[table_name] = count\n",
    "                except Exception as count_error:\n",
    "                    print(f\"ERROR: {count_error}\")\n",
    "                    counts[table_name] = 'Error'\n",
    "\n",
    "        print(\"--- MariaDB Table Row Counts ---\")\n",
    "        for table, count in counts.items():\n",
    "            print(f\"{table:<{max_len}} : {count}\")\n",
    "        print(\"---------------------------------\")\n",
    "        return counts\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f5ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MariaDB Operations Execution\n",
    "\n",
    "# # Schema initialization\n",
    "# with open('schemas/mariadb_schema.sql', 'r') as f:\n",
    "#     mariadb_schema = f.read()\n",
    "\n",
    "# initialize_mariadb_schema(mariadb_client, mariadb_schema)\n",
    "\n",
    "# # Table verification\n",
    "# required_tables = ['teachers', 'subjects', 'classes', 'students', 'enrollments', 'grades', 'schedules']\n",
    "# verify_mariadb_tables(mariadb_client, required_tables)\n",
    "\n",
    "# # Data loading\n",
    "# load_mariadb_data(mariadb_client, scale_100_dir)\n",
    "\n",
    "# # Count verification\n",
    "# verify_mariadb_counts(mariadb_client, required_tables)\n",
    "# CELL_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1eb7b3",
   "metadata": {},
   "source": [
    "# MongoDB Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB Methods\n",
    "def initialize_mongo_schema(client, db_name='benchmark'):\n",
    "    \"\"\"\n",
    "    Initializes the MongoDB schema by creating necessary collections.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        db = client[db_name]\n",
    "        \n",
    "        # List of collections to create based on no_sql_design.txt\n",
    "        collections = ['students', 'teachers', 'classes', 'subjects']\n",
    "        \n",
    "        # Drop existing collections if they exist\n",
    "        for collection in collections:\n",
    "            if collection in db.list_collection_names():\n",
    "                db[collection].drop()\n",
    "                print(f\"INFO: Dropped MongoDB collection: {collection}\")\n",
    "        \n",
    "        # Create collections with indexes\n",
    "        for collection in collections:\n",
    "            db.create_collection(collection)\n",
    "            print(f\"INFO: Created MongoDB collection: {collection}\")\n",
    "            \n",
    "            # Create indexes for performance\n",
    "            if collection == 'students':\n",
    "                db[collection].create_index([(\"last_name\", 1), (\"first_name\", 1)])\n",
    "            elif collection == 'classes':\n",
    "                db[collection].create_index([(\"name\", 1)])\n",
    "                \n",
    "        print(\"INFO: MongoDB schema initialized.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "\n",
    "def verify_mongo_collections(client, db_name='benchmark', expected_collections=None):\n",
    "    \"\"\"\n",
    "    Verifies if the expected collections exist in MongoDB.\n",
    "    \"\"\"\n",
    "    if expected_collections is None:\n",
    "        expected_collections = ['students', 'teachers', 'classes', 'subjects']\n",
    "    \n",
    "    try:\n",
    "        db = client[db_name]\n",
    "        existing_collections = db.list_collection_names()\n",
    "        \n",
    "        missing_collections = set(expected_collections) - set(existing_collections)\n",
    "        if not missing_collections:\n",
    "            print(f\"INFO: All MongoDB collections exist: {', '.join(expected_collections)}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"WARNING: Missing MongoDB collections: {', '.join(missing_collections)}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return False\n",
    "\n",
    "def insert_mongo_data_from_csv(client, collection_name, csv_file) -> tuple[float, float, float]:\n",
    "    operation_start_time = time.time() # Initialize start_time\n",
    "    file_opened_start_time = 0 # Initialize file_opened_start_time\n",
    "    try:\n",
    "        db = client['benchmark']\n",
    "        collection = db[collection_name]\n",
    "        \n",
    "        with open(csv_file, 'r') as f:\n",
    "            reader = pd.read_csv(f)\n",
    "            # rename id to _id for MongoDB\n",
    "            if 'id' in reader.columns:\n",
    "                reader.rename(columns={'id': '_id'}, inplace=True)\n",
    "\n",
    "            file_opened_start_time = time.time() # Initialize start_time just before starting to insert\n",
    "            for _, row in reader.iterrows():\n",
    "                doc = row.to_dict()\n",
    "                collection.insert_one(doc)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def insert_mongo_students_from_csv(client, data_path) -> tuple[float, float]:\n",
    "    # load all grades and enrollments into students from csv files\n",
    "    # create a student object with embedded enrollments and grades\n",
    "    students_file = data_path / 'students.csv'\n",
    "    enrollments_file = data_path / 'enrollments.csv'\n",
    "    grades_file = data_path / 'grades.csv'\n",
    "    operation_start_time = time.time() # Initialize start_time\n",
    "\n",
    "    try:\n",
    "        db = client['benchmark']\n",
    "        collection = db['students']\n",
    "        \n",
    "        with open(students_file, 'r') as f:\n",
    "            reader = pd.read_csv(f)\n",
    "            for _, row in reader.iterrows():\n",
    "                student_doc = {\n",
    "                    \"_id\": row['id'],\n",
    "                    \"first_name\": row['first_name'],\n",
    "                    \"last_name\": row['last_name'],\n",
    "                    \"birth_date\": row['birth_date'],\n",
    "                    \"enrollments\": [],\n",
    "                    \"grades\": []\n",
    "                }\n",
    "                collection.insert_one(student_doc)\n",
    "\n",
    "        with open(enrollments_file, 'r') as f:\n",
    "            reader = pd.read_csv(f)\n",
    "            for _, row in reader.iterrows():\n",
    "                student_id = row['student_id']\n",
    "                enrollment_doc = {\n",
    "                    \"class_id\": row['class_id'],\n",
    "                    \"enrolled_at\": row['enrolled_at']\n",
    "                }\n",
    "                collection.update_one(\n",
    "                    {\"_id\": student_id},\n",
    "                    {\"$push\": {\"enrollments\": enrollment_doc}}\n",
    "                )\n",
    "\n",
    "        with open(grades_file, 'r') as f:\n",
    "            reader = pd.read_csv(f)\n",
    "            for _, row in reader.iterrows():\n",
    "                student_id = row['student_id']\n",
    "                grade_doc = {\n",
    "                    \"subject_id\": row['subject_id'],\n",
    "                    \"grade\": row['grade'],\n",
    "                    \"created_at\": row['created_at']\n",
    "                }\n",
    "                collection.update_one(\n",
    "                    {\"_id\": student_id},\n",
    "                    {\"$push\": {\"grades\": grade_doc}}\n",
    "                )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        return (operation_start_time, end_time)\n",
    "\n",
    "\n",
    "def insert_mongo_classes_from_csv(client, data_path) -> tuple[float, float]:\n",
    "    # load all teachers and schedules into classes from csv files\n",
    "    # create a class object with embedded teachers and schedules\n",
    "    classes_file = data_path / 'classes.csv'\n",
    "    schedules_file = data_path / 'schedules.csv'\n",
    "    operation_start_time = time.time() # Initialize start_time\n",
    "\n",
    "    try:\n",
    "        db = client['benchmark']\n",
    "        collection = db['classes']\n",
    "\n",
    "        with open(classes_file, 'r') as f:\n",
    "            reader = pd.read_csv(f)\n",
    "            for _, row in reader.iterrows():\n",
    "                class_doc = {\n",
    "                    \"_id\": row['id'],\n",
    "                    \"name\": row['name'],\n",
    "                    \"teacher_id\": row['teacher_id'],\n",
    "                    \"schedule\": []\n",
    "                }\n",
    "                collection.insert_one(class_doc)\n",
    "\n",
    "        with open(schedules_file, 'r') as f:\n",
    "            reader = pd.read_csv(f)\n",
    "            for _, row in reader.iterrows():\n",
    "                class_id = row['class_id']\n",
    "                schedule_doc = {\n",
    "                    \"subject_id\": row['subject_id'],\n",
    "                    \"day_of_week\": row['day_of_week'],\n",
    "                    \"time_start\": row['time_start'],\n",
    "                    \"time_end\": row['time_end']\n",
    "                }\n",
    "                collection.update_one(\n",
    "                    {\"_id\": class_id},\n",
    "                    {\"$push\": {\"schedule\": schedule_doc}}\n",
    "                )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        return (operation_start_time, end_time)\n",
    "\n",
    "def load_mongo_data(client, data_dir):\n",
    "    data_path = Path(data_dir)\n",
    "    insert_mongo_data_from_csv(client, 'teachers', data_path / 'teachers.csv')\n",
    "    insert_mongo_data_from_csv(client, 'subjects', data_path / 'subjects.csv')\n",
    "    insert_mongo_students_from_csv(client, data_path)\n",
    "    insert_mongo_classes_from_csv(client, data_path)\n",
    "\n",
    "def verify_mongo_counts(client, db_name='benchmark'):\n",
    "    \"\"\"\n",
    "    Counts documents in MongoDB collections.\n",
    "    \"\"\"\n",
    "    collections = ['students', 'teachers', 'classes', 'subjects']\n",
    "    max_len = max(len(c) for c in collections)\n",
    "    \n",
    "    try:\n",
    "        db = client[db_name]\n",
    "        counts = {}\n",
    "        \n",
    "        for collection in collections:\n",
    "            try:\n",
    "                count = db[collection].count_documents({})\n",
    "                counts[collection] = count\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: {e}\")\n",
    "                counts[collection] = 'Error'\n",
    "                \n",
    "        print(\"--- MongoDB Collection Document Counts ---\")\n",
    "        for collection, count in counts.items():\n",
    "            print(f\"{collection:<{max_len}} : {count}\")\n",
    "        print(\"-----------------------------------------\")\n",
    "\n",
    "        # Additional checks for embedded documents\n",
    "        try:\n",
    "            students_with_enrollments = db.students.count_documents({\"enrollments\": {\"$exists\": True, \"$ne\": []}})\n",
    "            students_with_grades = db.students.count_documents({\"grades\": {\"$exists\": True, \"$ne\": []}})\n",
    "            classes_with_schedules = db.classes.count_documents({\"schedule\": {\"$exists\": True, \"$ne\": []}})\n",
    "            \n",
    "            print(\"\\n--- MongoDB Embedded Document Counts ---\")\n",
    "            print(f\"Students with enrollments : {students_with_enrollments}\")\n",
    "            print(f\"Students with grades      : {students_with_grades}\")\n",
    "            print(f\"Classes with schedules    : {classes_with_schedules}\")\n",
    "            print(\"-----------------------------------------\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: {e}\")\n",
    "        \n",
    "        return counts\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14fdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB Operations Execution\n",
    "\n",
    "# Schema initialization\n",
    "initialize_mongo_schema(mongo_client)\n",
    "\n",
    "# Collection verification\n",
    "verify_mongo_collections(mongo_client)\n",
    "\n",
    "# Data loading\n",
    "load_mongo_data(mongo_client, scale_100_dir)\n",
    "\n",
    "# Document count verification\n",
    "verify_mongo_counts(mongo_client)\n",
    "CELL_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eff04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cassandra data loading functions with minimal memory usage\n",
    "\n",
    "def initialize_cassandra_schema(session, keyspace='benchmark'):\n",
    "    \"\"\"Initializes the Cassandra schema by creating necessary keyspace and tables.\"\"\"\n",
    "    try:\n",
    "        # Create keyspace if not exists\n",
    "        session.execute(f\"\"\"\n",
    "            CREATE KEYSPACE IF NOT EXISTS {keyspace} \n",
    "            WITH REPLICATION = {{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }};\n",
    "        \"\"\")\n",
    "        \n",
    "        # Use the keyspace\n",
    "        session.execute(f\"USE {keyspace};\")\n",
    "        \n",
    "        # Drop existing tables if they exist\n",
    "        tables = ['teachers', 'subjects', 'classes', 'students', \n",
    "                'enrollments', 'grades', 'schedules', \n",
    "                'teacher_students', 'student_schedules', \n",
    "                'student_grades_with_descriptions_and_classes']\n",
    "        \n",
    "        for table in tables:\n",
    "            session.execute(f\"DROP TABLE IF EXISTS {table};\")\n",
    "            print(f\"INFO: Dropped Cassandra table: {table}\")\n",
    "        \n",
    "        # Create tables with appropriate data types\n",
    "        session.execute(\"\"\"\n",
    "            CREATE TABLE teachers (\n",
    "                id INT PRIMARY KEY,\n",
    "                first_name TEXT,\n",
    "                last_name TEXT\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        session.execute(\"\"\"\n",
    "            CREATE TABLE subjects (\n",
    "                id INT PRIMARY KEY,\n",
    "                name TEXT,\n",
    "                description TEXT\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        session.execute(\"\"\"\n",
    "            CREATE TABLE classes (\n",
    "                id INT PRIMARY KEY,\n",
    "                name TEXT,\n",
    "                teacher_id INT\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        session.execute(\"\"\"\n",
    "            CREATE TABLE students (\n",
    "                id INT PRIMARY KEY,\n",
    "                first_name TEXT,\n",
    "                last_name TEXT,\n",
    "                birth_date TEXT\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        session.execute(\"\"\"\n",
    "            CREATE TABLE enrollments (\n",
    "                student_id INT,\n",
    "                class_id INT,\n",
    "                enrolled_at TIMESTAMP,\n",
    "                PRIMARY KEY (student_id, class_id)\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        session.execute(\"\"\"\n",
    "            CREATE TABLE grades (\n",
    "                id INT PRIMARY KEY,\n",
    "                student_id INT,\n",
    "                subject_id INT,\n",
    "                grade FLOAT,\n",
    "                created_at TIMESTAMP\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        session.execute(\"\"\"\n",
    "            CREATE TABLE schedules (\n",
    "                id INT PRIMARY KEY,\n",
    "                class_id INT,\n",
    "                subject_id INT,\n",
    "                day_of_week TEXT,\n",
    "                time_start TEXT,\n",
    "                time_end TEXT\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        session.execute(\"\"\"\n",
    "            CREATE TABLE teacher_students (\n",
    "                teacher_id INT,\n",
    "                teacher_first_name TEXT,\n",
    "                teacher_last_name TEXT,\n",
    "                student_id INT,\n",
    "                student_first_name TEXT,\n",
    "                student_last_name TEXT,\n",
    "                student_birth_date TEXT,\n",
    "                PRIMARY KEY (teacher_id, student_id)\n",
    "            ) WITH CLUSTERING ORDER BY (student_id ASC);\n",
    "        \"\"\")\n",
    "        \n",
    "        session.execute(\"\"\"\n",
    "            CREATE TABLE student_schedules (\n",
    "                student_id INT,\n",
    "                student_first_name TEXT,\n",
    "                student_last_name TEXT,\n",
    "                student_birth_date TEXT,\n",
    "                schedule_id INT,\n",
    "                schedule_class_id INT,\n",
    "                schedule_subject_id INT,\n",
    "                schedule_day_of_week TEXT,\n",
    "                schedule_time_start TEXT,\n",
    "                schedule_time_end TEXT,    \n",
    "                PRIMARY KEY (student_id, schedule_id)\n",
    "            ) WITH CLUSTERING ORDER BY (schedule_id ASC);\n",
    "        \"\"\")\n",
    "\n",
    "        session.execute(\"\"\"\n",
    "            CREATE TABLE student_grades_with_descriptions_and_classes (\n",
    "                student_id INT,\n",
    "                class_id INT,\n",
    "                subject_id INT,\n",
    "                grade_id INT,\n",
    "                student_first_name TEXT,\n",
    "                student_last_name TEXT,\n",
    "                subject_name TEXT,\n",
    "                subject_description TEXT,\n",
    "                class_name TEXT,\n",
    "                grade FLOAT,\n",
    "                created_at TIMESTAMP,\n",
    "                PRIMARY KEY ((class_id), student_id, subject_id, grade_id)\n",
    "            ) WITH CLUSTERING ORDER BY (student_id ASC, subject_id ASC, grade_id ASC);\n",
    "        \"\"\")\n",
    "\n",
    "        print(\"INFO: Cassandra schema initialized.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "\n",
    "def verify_cassandra_tables(session, keyspace='benchmark', expected_tables=None):\n",
    "    \"\"\"Verifies if the expected tables exist in Cassandra.\"\"\"\n",
    "    if expected_tables is None:\n",
    "        expected_tables = ['teachers', 'subjects', 'classes', 'students', \n",
    "                            'enrollments', 'grades', 'schedules']\n",
    "    \n",
    "    try:\n",
    "        # Get existing tables\n",
    "        query = f\"\"\"\n",
    "            SELECT table_name FROM system_schema.tables \n",
    "            WHERE keyspace_name = '{keyspace}';\n",
    "        \"\"\"\n",
    "        rows = session.execute(query)\n",
    "        existing_tables = {row.table_name for row in rows}\n",
    "        \n",
    "        missing_tables = set(expected_tables) - existing_tables\n",
    "        if not missing_tables:\n",
    "            print(f\"INFO: All Cassandra tables exist: {', '.join(expected_tables)}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"WARNING: Missing Cassandra tables: {', '.join(missing_tables)}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return False\n",
    "\n",
    "def insert_cassandra_teachers(session, csv_file, keyspace='benchmark') -> tuple:\n",
    "    \"\"\"Insert teacher data from CSV, line by line.\"\"\"\n",
    "    operation_start_time = time.time()\n",
    "    file_opened_start_time = 0\n",
    "    \n",
    "    try:\n",
    "        # Use the keyspace\n",
    "        session.execute(f\"USE {keyspace};\")\n",
    "        \n",
    "        # Prepare the insert statement\n",
    "        prepared_stmt = session.prepare(\n",
    "            \"INSERT INTO teachers (id, first_name, last_name) VALUES (?, ?, ?)\"\n",
    "        )\n",
    "        \n",
    "        # Process CSV file line by line\n",
    "        with open(csv_file, 'r') as f:\n",
    "            # Skip header\n",
    "            header = next(f)\n",
    "            file_opened_start_time = time.time()\n",
    "            \n",
    "            for line in f:\n",
    "                values = line.strip().split(',')\n",
    "                if len(values) >= 3:  # Ensure we have enough columns\n",
    "                    session.execute(prepared_stmt, [\n",
    "                        int(values[0]),       # id\n",
    "                        values[1],            # first_name\n",
    "                        values[2]             # last_name\n",
    "                    ])\n",
    "        \n",
    "        print(\"INFO: Inserted teachers successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load teachers: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def insert_cassandra_subjects(session, csv_file, keyspace='benchmark') -> tuple:\n",
    "    \"\"\"Insert subject data from CSV, line by line.\"\"\"\n",
    "    operation_start_time = time.time()\n",
    "    file_opened_start_time = 0\n",
    "    \n",
    "    try:\n",
    "        # Use the keyspace\n",
    "        session.execute(f\"USE {keyspace};\")\n",
    "        \n",
    "        # Prepare the insert statement\n",
    "        prepared_stmt = session.prepare(\n",
    "            \"INSERT INTO subjects (id, name, description) VALUES (?, ?, ?)\"\n",
    "        )\n",
    "        \n",
    "        # Process CSV file line by line\n",
    "        with open(csv_file, 'r') as f:\n",
    "            # Skip header\n",
    "            header = next(f)\n",
    "            file_opened_start_time = time.time()\n",
    "            \n",
    "            for line in f:\n",
    "                values = line.strip().split(',')\n",
    "                if len(values) >= 3:  # Ensure we have enough columns\n",
    "                    session.execute(prepared_stmt, [\n",
    "                        int(values[0]),       # id\n",
    "                        values[1],            # name\n",
    "                        values[2]             # description\n",
    "                    ])\n",
    "        \n",
    "        print(\"INFO: Inserted subjects successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load subjects: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def insert_cassandra_classes(session, csv_file, keyspace='benchmark') -> tuple:\n",
    "    \"\"\"Insert class data from CSV, line by line.\"\"\"\n",
    "    operation_start_time = time.time()\n",
    "    file_opened_start_time = 0\n",
    "    \n",
    "    try:\n",
    "        # Use the keyspace\n",
    "        session.execute(f\"USE {keyspace};\")\n",
    "        \n",
    "        # Prepare the insert statement\n",
    "        prepared_stmt = session.prepare(\n",
    "            \"INSERT INTO classes (id, name, teacher_id) VALUES (?, ?, ?)\"\n",
    "        )\n",
    "        \n",
    "        # Process CSV file line by line\n",
    "        with open(csv_file, 'r') as f:\n",
    "            # Skip header\n",
    "            header = next(f)\n",
    "            file_opened_start_time = time.time()\n",
    "            \n",
    "            for line in f:\n",
    "                values = line.strip().split(',')\n",
    "                if len(values) >= 3:  # Ensure we have enough columns\n",
    "                    session.execute(prepared_stmt, [\n",
    "                        int(values[0]),       # id\n",
    "                        values[1],            # name\n",
    "                        int(values[2])        # teacher_id\n",
    "                    ])\n",
    "        \n",
    "        print(\"INFO: Inserted classes successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load classes: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def insert_cassandra_students(session, csv_file, keyspace='benchmark') -> tuple:\n",
    "    \"\"\"Insert student data from CSV, line by line.\"\"\"\n",
    "    operation_start_time = time.time()\n",
    "    file_opened_start_time = 0\n",
    "    \n",
    "    try:\n",
    "        # Use the keyspace\n",
    "        session.execute(f\"USE {keyspace};\")\n",
    "        \n",
    "        # Prepare the insert statement\n",
    "        prepared_stmt = session.prepare(\n",
    "            \"INSERT INTO students (id, first_name, last_name, birth_date) VALUES (?, ?, ?, ?)\"\n",
    "        )\n",
    "        \n",
    "        # Process CSV file line by line\n",
    "        with open(csv_file, 'r') as f:\n",
    "            # Skip header\n",
    "            header = next(f)\n",
    "            file_opened_start_time = time.time()\n",
    "            \n",
    "            for line in f:\n",
    "                values = line.strip().split(',')\n",
    "                if len(values) >= 4:  # Ensure we have enough columns\n",
    "                    session.execute(prepared_stmt, [\n",
    "                        int(values[0]),       # id\n",
    "                        values[1],            # first_name\n",
    "                        values[2],            # last_name\n",
    "                        values[3]             # birth_date\n",
    "                    ])\n",
    "        \n",
    "        print(\"INFO: Inserted students successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load students: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def insert_cassandra_enrollments(session, csv_file, keyspace='benchmark') -> tuple:\n",
    "    \"\"\"Insert enrollment data from CSV, line by line, with timestamp handling.\"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    operation_start_time = time.time()\n",
    "    file_opened_start_time = 0\n",
    "    \n",
    "    try:\n",
    "        # Use the keyspace\n",
    "        session.execute(f\"USE {keyspace};\")\n",
    "        \n",
    "        # Prepare the insert statement\n",
    "        prepared_stmt = session.prepare(\n",
    "            \"INSERT INTO enrollments (student_id, class_id, enrolled_at) VALUES (?, ?, ?)\"\n",
    "        )\n",
    "        \n",
    "        # Process CSV file line by line\n",
    "        with open(csv_file, 'r') as f:\n",
    "            # Skip header\n",
    "            header = next(f)\n",
    "            file_opened_start_time = time.time()\n",
    "            \n",
    "            for line in f:\n",
    "                values = line.strip().split(',')\n",
    "                if len(values) >= 3:  # Ensure we have enough columns\n",
    "                    # Convert timestamp string to datetime object\n",
    "                    enrolled_at = datetime.fromisoformat(values[2].replace('Z', '+00:00'))\n",
    "                    \n",
    "                    session.execute(prepared_stmt, [\n",
    "                        int(values[0]),       # student_id\n",
    "                        int(values[1]),       # class_id\n",
    "                        enrolled_at           # enrolled_at as datetime\n",
    "                    ])\n",
    "        \n",
    "        print(\"INFO: Inserted enrollments successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load enrollments: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def insert_cassandra_grades(session, csv_file, keyspace='benchmark') -> tuple:\n",
    "    \"\"\"Insert grades data from CSV, line by line, with UUID and timestamp handling.\"\"\"\n",
    "    from datetime import datetime\n",
    "    from uuid import uuid4\n",
    "    \n",
    "    operation_start_time = time.time()\n",
    "    file_opened_start_time = 0\n",
    "    \n",
    "    try:\n",
    "        # Use the keyspace\n",
    "        session.execute(f\"USE {keyspace};\")\n",
    "        \n",
    "        # Prepare the insert statement\n",
    "        prepared_stmt = session.prepare(\n",
    "            \"INSERT INTO grades (id, student_id, subject_id, grade, created_at) VALUES (?, ?, ?, ?, ?)\"\n",
    "        )\n",
    "        \n",
    "        # Process CSV file line by line\n",
    "        with open(csv_file, 'r') as f:\n",
    "            # Skip header\n",
    "            header = next(f)\n",
    "            file_opened_start_time = time.time()\n",
    "            \n",
    "            for line in f:\n",
    "                values = line.strip().split(',')\n",
    "                if len(values) >= 4:  # Ensure we have enough columns\n",
    "                    # Convert timestamp string to datetime object\n",
    "                    created_at = datetime.fromisoformat(values[4].replace('Z', '+00:00'))\n",
    "                    \n",
    "                    session.execute(prepared_stmt, [\n",
    "                        int(values[0]),              # id (generated UUID)\n",
    "                        int(values[1]),       # student_id\n",
    "                        int(values[2]),       # subject_id\n",
    "                        float(values[3]),     # grade\n",
    "                        created_at            # created_at as datetime\n",
    "                    ])\n",
    "        \n",
    "        print(\"INFO: Inserted grades successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load grades: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def insert_cassandra_schedules(session, csv_file, keyspace='benchmark') -> tuple:\n",
    "    \"\"\"Insert schedule data from CSV, line by line, with UUID and day mapping.\"\"\"\n",
    "    from uuid import uuid4\n",
    "    \n",
    "    operation_start_time = time.time()\n",
    "    file_opened_start_time = 0\n",
    "    \n",
    "    try:\n",
    "        # Use the keyspace\n",
    "        session.execute(f\"USE {keyspace};\")\n",
    "        \n",
    "        # Prepare the insert statement\n",
    "        prepared_stmt = session.prepare(\n",
    "            \"INSERT INTO schedules (id, class_id, subject_id, day_of_week, time_start, time_end) VALUES (?, ?, ?, ?, ?, ?)\"\n",
    "        )\n",
    "        \n",
    "        # Process CSV file line by line\n",
    "        with open(csv_file, 'r') as f:\n",
    "            # Skip header\n",
    "            header = next(f)\n",
    "            file_opened_start_time = time.time()\n",
    "            \n",
    "            for line in f:\n",
    "                values = line.strip().split(',')\n",
    "                if len(values) >= 6:  # Ensure we have enough columns\n",
    "                    session.execute(prepared_stmt, [\n",
    "                        int(values[0]),              # id (generated UUID)\n",
    "                        int(values[1]),       # class_id\n",
    "                        int(values[2]),       # subject_id\n",
    "                        values[3],            # day_of_week\n",
    "                        values[4],            # time_start\n",
    "                        values[5]             # time_end\n",
    "                    ])\n",
    "        \n",
    "        print(\"INFO: Inserted schedules successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load schedules: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return (operation_start_time, file_opened_start_time, end_time)\n",
    "\n",
    "def populate_cassandra_denormalized_tables2(session, data_dir, keyspace='benchmark'):\n",
    "    # 1. populate table teacher_students which will consist all students taught by same teacher\n",
    "    # 2. populate table student_schedules which will consist of all schedules for the student\n",
    "    # 3. populate table student_grades_with_descriptions_and_classes which will consist of all grades with the subjects descriptions for all students in the class\n",
    "    pass\n",
    "\n",
    "def populate_cassandra_denormalized_tables(session, data_dir, keyspace='benchmark'):\n",
    "    \"\"\"\n",
    "    Populates denormalized tables for optimized query performance.\n",
    "    Uses a Cassandra-friendly approach without relying on JOIN operations.\n",
    "    \n",
    "    Args:\n",
    "        session: Cassandra session\n",
    "        data_dir: Directory containing CSV data files\n",
    "        keyspace: Cassandra keyspace name\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    \n",
    "    print(\"INFO: Populating denormalized tables - this might take a while for large datasets\")\n",
    "    session.execute(f\"USE {keyspace};\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1. Populate teacher_students table\n",
    "    print(\"INFO: Populating teacher_students table...\")\n",
    "    \n",
    "    # First get all teachers\n",
    "    teachers = {}\n",
    "    for teacher_row in session.execute(\"SELECT id, first_name, last_name FROM teachers\"):\n",
    "        teachers[teacher_row.id] = (teacher_row.first_name, teacher_row.last_name)\n",
    "    \n",
    "    # Get all classes with their teacher_ids\n",
    "    class_teachers = {}\n",
    "    for class_row in session.execute(\"SELECT id, teacher_id FROM classes\"):\n",
    "        class_teachers[class_row.id] = class_row.teacher_id\n",
    "    \n",
    "    # Get all student-class relationships from enrollments\n",
    "    enrollments_query = session.execute(\"SELECT student_id, class_id FROM enrollments\")\n",
    "    \n",
    "    # Get all students\n",
    "    students = {}\n",
    "    for student_row in session.execute(\"SELECT id, first_name, last_name, birth_date FROM students\"):\n",
    "        students[student_row.id] = (student_row.first_name, student_row.last_name, student_row.birth_date)\n",
    "    \n",
    "    # Prepare statement for inserting into teacher_students\n",
    "    teacher_students_insert = session.prepare(\"\"\"\n",
    "        INSERT INTO teacher_students (\n",
    "            teacher_id, teacher_first_name, teacher_last_name,\n",
    "            student_id, student_first_name, student_last_name, student_birth_date\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    \n",
    "    # Process and insert teacher-student relationships\n",
    "    teacher_student_count = 0\n",
    "    for enrollment in enrollments_query:\n",
    "        student_id = enrollment.student_id\n",
    "        class_id = enrollment.class_id\n",
    "        \n",
    "        if student_id in students and class_id in class_teachers:\n",
    "            teacher_id = class_teachers[class_id]\n",
    "            \n",
    "            if teacher_id in teachers:\n",
    "                # Get teacher and student data\n",
    "                teacher_first_name, teacher_last_name = teachers[teacher_id]\n",
    "                student_first_name, student_last_name, student_birth_date = students[student_id]\n",
    "                \n",
    "                # Insert into denormalized table\n",
    "                session.execute(teacher_students_insert, (\n",
    "                    teacher_id, teacher_first_name, teacher_last_name,\n",
    "                    student_id, student_first_name, student_last_name, student_birth_date\n",
    "                ))\n",
    "                teacher_student_count += 1\n",
    "                \n",
    "                if teacher_student_count % 10000 == 0:\n",
    "                    print(f\"INFO: Inserted {teacher_student_count} teacher-student relationships\")\n",
    "    \n",
    "    print(f\"INFO: Completed teacher_students table with {teacher_student_count} relationships\")\n",
    "    \n",
    "    # 2. Populate student_schedules table\n",
    "    print(\"INFO: Populating student_schedules table...\")\n",
    "    \n",
    "    # Get all schedules\n",
    "    schedules = {}\n",
    "    schedule_rows = session.execute(\n",
    "        \"SELECT id, class_id, subject_id, day_of_week, time_start, time_end FROM schedules\"\n",
    "    )\n",
    "    \n",
    "    for schedule_row in schedule_rows:\n",
    "        schedules[schedule_row.id] = (\n",
    "            schedule_row.class_id, \n",
    "            schedule_row.subject_id, \n",
    "            schedule_row.day_of_week, \n",
    "            schedule_row.time_start, \n",
    "            schedule_row.time_end\n",
    "        )\n",
    "    \n",
    "    # Map classes to their schedules\n",
    "    class_schedules = {}\n",
    "    for schedule_id, (class_id, subject_id, day, start, end) in schedules.items():\n",
    "        if class_id not in class_schedules:\n",
    "            class_schedules[class_id] = []\n",
    "        class_schedules[class_id].append((schedule_id, subject_id, day, start, end))\n",
    "    \n",
    "    # Prepare statement for inserting into student_schedules\n",
    "    student_schedules_insert = session.prepare(\"\"\"\n",
    "        INSERT INTO student_schedules (\n",
    "            student_id, student_first_name, student_last_name, student_birth_date,\n",
    "            schedule_id, schedule_class_id, schedule_subject_id,\n",
    "            schedule_day_of_week, schedule_time_start, schedule_time_end\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    \n",
    "    # Reset enrollment query\n",
    "    enrollments_query = session.execute(\"SELECT student_id, class_id FROM enrollments\")\n",
    "    \n",
    "    # Process and insert student schedules\n",
    "    schedule_count = 0\n",
    "    for enrollment in enrollments_query:\n",
    "        student_id = enrollment.student_id\n",
    "        class_id = enrollment.class_id\n",
    "        \n",
    "        if student_id in students and class_id in class_schedules:\n",
    "            student_first_name, student_last_name, student_birth_date = students[student_id]\n",
    "            \n",
    "            # Add each schedule for this student's class\n",
    "            for schedule_id, subject_id, day, start, end in class_schedules[class_id]:\n",
    "                session.execute(student_schedules_insert, (\n",
    "                    student_id, student_first_name, student_last_name, student_birth_date,\n",
    "                    schedule_id, class_id, subject_id, day, start, end\n",
    "                ))\n",
    "                schedule_count += 1\n",
    "                \n",
    "                if schedule_count % 10000 == 0:\n",
    "                    print(f\"INFO: Inserted {schedule_count} student schedule entries\")\n",
    "    \n",
    "    print(f\"INFO: Completed student_schedules table with {schedule_count} entries\")\n",
    "    \n",
    "    # 3. Populate student_grades_with_descriptions_and_classes table\n",
    "    print(\"INFO: Populating student_grades_with_descriptions_and_classes table...\")\n",
    "    \n",
    "    # Get all subjects with their descriptions\n",
    "    subjects = {}\n",
    "    for subject_row in session.execute(\"SELECT id, name, description FROM subjects\"):\n",
    "        subjects[subject_row.id] = (subject_row.name, subject_row.description)\n",
    "    \n",
    "    # Get all classes with names\n",
    "    classes = {}\n",
    "    for class_row in session.execute(\"SELECT id, name FROM classes\"):\n",
    "        classes[class_row.id] = class_row.name\n",
    "    \n",
    "    # Get all grades\n",
    "    grades = []\n",
    "    for grade_row in session.execute(\"SELECT id, student_id, subject_id, grade, created_at FROM grades\"):\n",
    "        grades.append((\n",
    "            grade_row.id,\n",
    "            grade_row.student_id,\n",
    "            grade_row.subject_id,\n",
    "            grade_row.grade,\n",
    "            grade_row.created_at\n",
    "        ))\n",
    "    \n",
    "    # Map students to their enrolled classes\n",
    "    student_classes = {}\n",
    "    enrollments_query = session.execute(\"SELECT student_id, class_id FROM enrollments\")\n",
    "    for enrollment in enrollments_query:\n",
    "        if enrollment.student_id not in student_classes:\n",
    "            student_classes[enrollment.student_id] = []\n",
    "        student_classes[enrollment.student_id].append(enrollment.class_id)\n",
    "    \n",
    "    # Prepare statement for inserting into student_grades_with_descriptions_and_classes\n",
    "    grades_insert = session.prepare(\"\"\"\n",
    "        INSERT INTO student_grades_with_descriptions_and_classes (\n",
    "            student_id, class_id, subject_id, grade_id,\n",
    "            student_first_name, student_last_name,\n",
    "            subject_name, subject_description, class_name,\n",
    "            grade, created_at\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    \n",
    "    # Process and insert student grades with descriptions\n",
    "    grade_count = 0\n",
    "    for grade_id, student_id, subject_id, grade_value, created_at in grades:\n",
    "        if (student_id in students and subject_id in subjects and \n",
    "            student_id in student_classes and len(student_classes[student_id]) > 0):\n",
    "            \n",
    "            student_first_name, student_last_name, _ = students[student_id]\n",
    "            subject_name, subject_description = subjects[subject_id]\n",
    "            \n",
    "            # For each class the student is enrolled in, add this grade record\n",
    "            for class_id in student_classes[student_id]:\n",
    "                if class_id in classes:\n",
    "                    class_name = classes[class_id]\n",
    "                    \n",
    "                    # Insert into denormalized table\n",
    "                    session.execute(grades_insert, (\n",
    "                        student_id, class_id, subject_id, grade_id,\n",
    "                        student_first_name, student_last_name,\n",
    "                        subject_name, subject_description, class_name,\n",
    "                        grade_value, created_at\n",
    "                    ))\n",
    "                    grade_count += 1\n",
    "                    \n",
    "                    if grade_count % 10000 == 0:\n",
    "                        print(f\"INFO: Inserted {grade_count} grade entries with descriptions\")\n",
    "    \n",
    "    print(f\"INFO: Completed student_grades_with_descriptions_and_classes table with {grade_count} entries\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"INFO: Populated all denormalized tables in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "def load_cassandra_data(session, data_dir, keyspace='benchmark'):\n",
    "    \"\"\"Load all data into Cassandra tables.\"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    # Use the keyspace\n",
    "    session.execute(f\"USE {keyspace};\")\n",
    "    \n",
    "    # Insert basic entities\n",
    "    op_time, f_op_time, end_time = insert_cassandra_teachers(session, data_path / 'teachers.csv')\n",
    "    print(f\"INFO: Inserted teachers in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "    \n",
    "    op_time, f_op_time, end_time = insert_cassandra_subjects(session, data_path / 'subjects.csv')\n",
    "    print(f\"INFO: Inserted subjects in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "    \n",
    "    op_time, f_op_time, end_time = insert_cassandra_classes(session, data_path / 'classes.csv')\n",
    "    print(f\"INFO: Inserted classes in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "    \n",
    "    op_time, f_op_time, end_time = insert_cassandra_students(session, data_path / 'students.csv')\n",
    "    print(f\"INFO: Inserted students in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "    \n",
    "    # Insert relationships and complex data\n",
    "    op_time, f_op_time, end_time = insert_cassandra_enrollments(session, data_path / 'enrollments.csv')\n",
    "    print(f\"INFO: Inserted enrollments in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "    \n",
    "    op_time, f_op_time, end_time = insert_cassandra_grades(session, data_path / 'grades.csv')\n",
    "    print(f\"INFO: Inserted grades in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "    \n",
    "    op_time, f_op_time, end_time = insert_cassandra_schedules(session, data_path / 'schedules.csv')\n",
    "    print(f\"INFO: Inserted schedules in {end_time - op_time:.2f} seconds (file opened in {end_time - f_op_time:.2f} seconds)\")\n",
    "    \n",
    "    # Populate denormalized tables\n",
    "    populate_cassandra_denormalized_tables(session, data_path)\n",
    "\n",
    "def verify_cassandra_counts(session, keyspace='benchmark'):\n",
    "    \"\"\"Count rows in all Cassandra tables.\"\"\"\n",
    "    tables = ['teachers', 'subjects', 'classes', 'students', \n",
    "                'enrollments', 'grades', 'schedules', \n",
    "                'teacher_students', 'student_schedules', 'student_grades_with_descriptions_and_classes']\n",
    "    max_len = max(len(t) for t in tables)\n",
    "    \n",
    "    try:\n",
    "        # Use the keyspace\n",
    "        session.execute(f\"USE {keyspace};\")\n",
    "        counts = {}\n",
    "        \n",
    "        for table in tables:\n",
    "            try:\n",
    "                rows = session.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "                count = rows.one()[0]\n",
    "                counts[table] = count\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: {e}\")\n",
    "                counts[table] = 'Error'\n",
    "        \n",
    "        print(\"--- Cassandra Table Row Counts ---\")\n",
    "        for table, count in counts.items():\n",
    "            print(f\"{table:<{max_len}} : {count}\")\n",
    "        print(\"----------------------------------\")\n",
    "        \n",
    "        return counts\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cassandra Operations Execution\n",
    "\n",
    "# # Schema initialization\n",
    "# initialize_cassandra_schema(cassandra_session)\n",
    "\n",
    "# # Table verification\n",
    "# required_tables = ['teachers', 'subjects', 'classes', 'students', \n",
    "#                 'enrollments', 'grades', 'schedules', \n",
    "#                 'teacher_students', 'student_schedules', 'student_grades_with_descriptions_and_classes']\n",
    "# verify_cassandra_tables(cassandra_session, expected_tables=required_tables)\n",
    "\n",
    "# # Data loading\n",
    "# load_cassandra_data(cassandra_session, scale_100_dir)\n",
    "\n",
    "# # Row count verification\n",
    "# verify_cassandra_counts(cassandra_session)\n",
    "# CELL_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61d5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postgres_operation(conn, query, fetch=False):\n",
    "    \"\"\"\n",
    "    Executes a PostgreSQL operation and returns the result.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            if fetch:\n",
    "                result = cur.fetchall()\n",
    "                if DEBUG:\n",
    "                    print(result)\n",
    "        \n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        conn.rollback()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mariadb_operation(conn, query, fetch=False):\n",
    "    \"\"\"\n",
    "    Executes a MariaDB operation and returns the result.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            if fetch:\n",
    "                result = cur.fetchall()\n",
    "                if DEBUG:\n",
    "                    print(result)\n",
    "        \n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        conn.rollback()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542996fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mongo_operation(client, db_name, collection_name, operation_type, query=None, data=None, options=None, fetch=False):\n",
    "    \"\"\"\n",
    "    Executes a MongoDB operation and returns the result.\n",
    "    \n",
    "    Args:\n",
    "        client: MongoDB client connection\n",
    "        db_name: Database name to operate on\n",
    "        collection_name: Collection name to operate on\n",
    "        operation_type: Type of operation ('find', 'insert', 'update', 'delete')\n",
    "        query: Query filter for find/update/delete operations (dict)\n",
    "        data: Data for insert/update operations (dict or list of dicts)\n",
    "        options: Additional options for operations (dict)\n",
    "        fetch: Whether to fetch and print results (boolean)\n",
    "        \n",
    "    Returns:\n",
    "        Operation result or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get database and collection references\n",
    "        db = client[db_name]\n",
    "        collection = db[collection_name]\n",
    "        result = None\n",
    "        \n",
    "        # Execute the requested operation\n",
    "        if operation_type == 'find':\n",
    "            # For find operations\n",
    "            query = query or {}\n",
    "            options = options or {}\n",
    "            cursor = collection.find(query, **options)\n",
    "            result = list(cursor)\n",
    "            if fetch and DEBUG:\n",
    "                print(result)\n",
    "                \n",
    "        elif operation_type == 'insert':\n",
    "            # For insert operations\n",
    "            if isinstance(data, list):\n",
    "                result = collection.insert_many(data)\n",
    "            else:\n",
    "                result = collection.insert_one(data)\n",
    "                \n",
    "        elif operation_type == 'update':\n",
    "            # For update operations\n",
    "            options = options or {}\n",
    "            if options.get('multi', False):\n",
    "                result = collection.update_many(query, data, **options)\n",
    "            else:\n",
    "                result = collection.update_one(query, data, **options)\n",
    "                \n",
    "        elif operation_type == 'delete':\n",
    "            # For delete operations\n",
    "            options = options or {}\n",
    "            if options.get('multi', False):\n",
    "                result = collection.delete_many(query, **options)\n",
    "            else:\n",
    "                result = collection.delete_one(query, **options)\n",
    "                \n",
    "        else:\n",
    "            print(f\"ERROR: Unsupported operation type: {operation_type}\")\n",
    "            return None\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812cd44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cassandra_operation(session, query, params=None, fetch=False, keyspace='benchmark'):\n",
    "    \"\"\"\n",
    "    Executes a Cassandra CQL operation and returns the result.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set the keyspace\n",
    "        session.execute(f\"USE {keyspace};\")\n",
    "        \n",
    "        # Execute the query with or without parameters\n",
    "        if params:\n",
    "            # For prepared statements, we need to prepare first\n",
    "            prepared = session.prepare(query)\n",
    "            result = session.execute(prepared, params)\n",
    "        else:\n",
    "            result = session.execute(query)\n",
    "        \n",
    "        # Rest of your function remains the same...\n",
    "        if fetch and query.strip().upper().startswith('SELECT'):\n",
    "            rows = list(result)\n",
    "            if DEBUG:\n",
    "                for row in rows:\n",
    "                    print(row)\n",
    "            return rows\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Cassandra operation failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb66048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id,first_name,last_name,subject,hire_date,created_at\n",
    "test_teachers = {\n",
    "    10000001: {\"first_name\": \"Anna\",    \"last_name\": \"Smith\",   \"subject\": \"Mathematics\",    \"hire_date\": \"2010-01-15\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000002: {\"first_name\": \"James\",   \"last_name\": \"Lee\",     \"subject\": \"History\",        \"hire_date\": \"2012-08-20\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000003: {\"first_name\": \"Maria\",   \"last_name\": \"Garcia\",  \"subject\": \"Biology\",        \"hire_date\": \"2015-03-10\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000004: {\"first_name\": \"David\",   \"last_name\": \"Johnson\", \"subject\": \"Chemistry\",      \"hire_date\": \"2011-11-01\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000005: {\"first_name\": \"Linda\",   \"last_name\": \"Brown\",   \"subject\": \"English\",        \"hire_date\": \"2013-04-22\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000006: {\"first_name\": \"Robert\",  \"last_name\": \"Jones\",   \"subject\": \"Physics\",        \"hire_date\": \"2014-09-30\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000007: {\"first_name\": \"Patricia\",\"last_name\": \"Miller\",  \"subject\": \"Art\",            \"hire_date\": \"2016-06-17\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000008: {\"first_name\": \"Michael\", \"last_name\": \"Davis\",   \"subject\": \"Geography\",      \"hire_date\": \"2009-02-05\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000009: {\"first_name\": \"Barbara\", \"last_name\": \"Wilson\",  \"subject\": \"Music\",          \"hire_date\": \"2017-12-12\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000010: {\"first_name\": \"William\", \"last_name\": \"Taylor\",  \"subject\": \"Computer Science\",\"hire_date\": \"2008-07-29\", \"created_at\": \"2025-05-05T12:00:00Z\"}\n",
    "}\n",
    "\n",
    "# id,name,description,created_at \n",
    "test_subjects = {\n",
    "    10000011: {\"name\": \"Mathematics\",        \"description\": \"Math fundamentals\",          \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000012: {\"name\": \"History\",            \"description\": \"World history overview\",    \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000013: {\"name\": \"Biology\",            \"description\": \"Life sciences\",             \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000014: {\"name\": \"Chemistry\",          \"description\": \"Chemical reactions\",        \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000015: {\"name\": \"English\",            \"description\": \"Literature and grammar\",    \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000016: {\"name\": \"Physics\",            \"description\": \"Mechanics and waves\",        \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000017: {\"name\": \"Art\",                \"description\": \"Art history and practice\",  \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000018: {\"name\": \"Geography\",          \"description\": \"Physical and human geo\",    \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000019: {\"name\": \"Music\",              \"description\": \"Theory and performance\",     \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000020: {\"name\": \"Computer Science\",   \"description\": \"Programming concepts\",      \"created_at\": \"2025-05-05T12:00:00Z\"}\n",
    "}\n",
    "\n",
    "# id,name,teacher_id,created_at\n",
    "test_classes = {\n",
    "    10000021: {\"name\": \"Algebra I\",      \"teacher_id\": 10000001, \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000022: {\"name\": \"World History\",  \"teacher_id\": 10000002, \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000023: {\"name\": \"Biology 101\",    \"teacher_id\": 10000003, \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000024: {\"name\": \"Organic Chemistry\",\"teacher_id\":10000004, \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000025: {\"name\": \"English Lit\",    \"teacher_id\": 10000005, \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000026: {\"name\": \"Physics I\",      \"teacher_id\": 10000006, \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000027: {\"name\": \"Drawing\",        \"teacher_id\": 10000007, \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000028: {\"name\": \"World Geography\",\"teacher_id\": 10000008, \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000029: {\"name\": \"Choir\",          \"teacher_id\": 10000009, \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000030: {\"name\": \"Intro to CS\",    \"teacher_id\": 10000010, \"created_at\": \"2025-05-05T12:00:00Z\"}\n",
    "}\n",
    "\n",
    "# id,first_name,last_name,birth_date,created_at\n",
    "test_students = {\n",
    "    10000031: {\"first_name\": \"John\",   \"last_name\": \"Doe\",    \"birth_date\": \"2005-06-15\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000032: {\"first_name\": \"Alice\",  \"last_name\": \"Wang\",   \"birth_date\": \"2006-11-02\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000033: {\"first_name\": \"Bob\",    \"last_name\": \"Nguyen\", \"birth_date\": \"2005-02-28\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000034: {\"first_name\": \"Carol\",  \"last_name\": \"Kim\",    \"birth_date\": \"2006-01-11\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000035: {\"first_name\": \"Eve\",    \"last_name\": \"Patel\",  \"birth_date\": \"2005-09-23\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000036: {\"first_name\": \"Frank\",  \"last_name\": \"Lopez\",  \"birth_date\": \"2006-07-05\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000037: {\"first_name\": \"Grace\",  \"last_name\": \"Chen\",   \"birth_date\": \"2005-12-19\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000038: {\"first_name\": \"Hank\",   \"last_name\": \"Singh\",  \"birth_date\": \"2006-03-30\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000039: {\"first_name\": \"Ivy\",    \"last_name\": \"Martinez\",\"birth_date\": \"2005-10-08\", \"created_at\": \"2025-05-05T12:00:00Z\"},\n",
    "    10000040: {\"first_name\": \"Jack\",   \"last_name\": \"Clark\",  \"birth_date\": \"2006-05-17\", \"created_at\": \"2025-05-05T12:00:00Z\"}\n",
    "}\n",
    "\n",
    "# student_id,class_id,enrolled_at\n",
    "test_enrollments = {\n",
    "    (10000031, 10000021): {\"enrolled_at\": \"2023-09-01T08:00:00Z\"},\n",
    "    (10000032, 10000022): {\"enrolled_at\": \"2023-09-02T09:00:00Z\"},\n",
    "    (10000033, 10000023): {\"enrolled_at\": \"2023-09-03T10:00:00Z\"},\n",
    "    (10000034, 10000024): {\"enrolled_at\": \"2023-09-04T11:00:00Z\"},\n",
    "    (10000035, 10000025): {\"enrolled_at\": \"2023-09-05T12:00:00Z\"},\n",
    "    (10000036, 10000026): {\"enrolled_at\": \"2023-09-06T13:00:00Z\"},\n",
    "    (10000037, 10000027): {\"enrolled_at\": \"2023-09-07T14:00:00Z\"},\n",
    "    (10000038, 10000028): {\"enrolled_at\": \"2023-09-08T15:00:00Z\"},\n",
    "    (10000039, 10000029): {\"enrolled_at\": \"2023-09-09T16:00:00Z\"},\n",
    "    (10000040, 10000030): {\"enrolled_at\": \"2023-09-10T17:00:00Z\"}\n",
    "}\n",
    "\n",
    "# id,class_id,subject_id,day_of_week,time_start,time_end\n",
    "test_schedules = {\n",
    "    10000051: {\"class_id\": 10000021, \"subject_id\": 10000011, \"day_of_week\": \"Monday\",    \"time_start\": \"08:00\", \"time_end\": \"09:30\"},\n",
    "    10000052: {\"class_id\": 10000022, \"subject_id\": 10000012, \"day_of_week\": \"Tuesday\",   \"time_start\": \"09:00\", \"time_end\": \"10:30\"},\n",
    "    10000053: {\"class_id\": 10000023, \"subject_id\": 10000013, \"day_of_week\": \"Wednesday\", \"time_start\": \"10:00\", \"time_end\": \"11:30\"},\n",
    "    10000054: {\"class_id\": 10000024, \"subject_id\": 10000014, \"day_of_week\": \"Thursday\",  \"time_start\": \"11:00\", \"time_end\": \"12:30\"},\n",
    "    10000055: {\"class_id\": 10000025, \"subject_id\": 10000015, \"day_of_week\": \"Friday\",    \"time_start\": \"12:00\", \"time_end\": \"13:30\"},\n",
    "    10000056: {\"class_id\": 10000026, \"subject_id\": 10000016, \"day_of_week\": \"Monday\",    \"time_start\": \"13:00\", \"time_end\": \"14:30\"},\n",
    "    10000057: {\"class_id\": 10000027, \"subject_id\": 10000017, \"day_of_week\": \"Tuesday\",   \"time_start\": \"14:00\", \"time_end\": \"15:30\"},\n",
    "    10000058: {\"class_id\": 10000028, \"subject_id\": 10000018, \"day_of_week\": \"Wednesday\", \"time_start\": \"15:00\", \"time_end\": \"16:30\"},\n",
    "    10000059: {\"class_id\": 10000029, \"subject_id\": 10000019, \"day_of_week\": \"Thursday\",  \"time_start\": \"16:00\", \"time_end\": \"17:30\"},\n",
    "    10000060: {\"class_id\": 10000030, \"subject_id\": 10000020, \"day_of_week\": \"Friday\",    \"time_start\": \"17:00\", \"time_end\": \"18:30\"}\n",
    "}\n",
    "\n",
    "# id,student_id,subject_id,grade,created_at\n",
    "test_grades = {\n",
    "    10000041: {\"student_id\": 10000031, \"subject_id\": 10000011, \"grade\": 85, \"created_at\": \"2024-05-10T12:00:00Z\"},\n",
    "    10000042: {\"student_id\": 10000032, \"subject_id\": 10000012, \"grade\": 92, \"created_at\": \"2024-06-15T14:30:00Z\"},\n",
    "    10000043: {\"student_id\": 10000033, \"subject_id\": 10000013, \"grade\": 78, \"created_at\": \"2024-07-20T16:45:00Z\"},\n",
    "    10000044: {\"student_id\": 10000034, \"subject_id\": 10000014, \"grade\": 88, \"created_at\": \"2024-08-22T10:15:00Z\"},\n",
    "    10000045: {\"student_id\": 10000035, \"subject_id\": 10000015, \"grade\": 91, \"created_at\": \"2024-09-05T09:00:00Z\"},\n",
    "    10000046: {\"student_id\": 10000036, \"subject_id\": 10000016, \"grade\": 79, \"created_at\": \"2024-10-12T11:20:00Z\"},\n",
    "    10000047: {\"student_id\": 10000037, \"subject_id\": 10000017, \"grade\": 94, \"created_at\": \"2024-11-30T13:50:00Z\"},\n",
    "    10000048: {\"student_id\": 10000038, \"subject_id\": 10000018, \"grade\": 82, \"created_at\": \"2024-12-18T15:05:00Z\"},\n",
    "    10000049: {\"student_id\": 10000039, \"subject_id\": 10000019, \"grade\": 76, \"created_at\": \"2025-01-25T08:40:00Z\"},\n",
    "    10000050: {\"student_id\": 10000040, \"subject_id\": 10000020, \"grade\": 89, \"created_at\": \"2025-02-14T14:10:00Z\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import statistics\n",
    "from typing import List, Tuple, Callable\n",
    "\n",
    "class SimpleBenchmark:\n",
    "    \"\"\"Benchmark utility that prints results and returns pandas DataFrame for comparison\"\"\"\n",
    "    \n",
    "    def __init__(self, db_type: str, data_dir: str):\n",
    "        self.data_dir = data_dir\n",
    "        self.db_type = db_type\n",
    "        self.process = psutil.Process()\n",
    "        self.results = []  # Store results for each scenario\n",
    "    \n",
    "    def get_results_df(self):\n",
    "        \"\"\"\n",
    "        Convert the results to a pandas DataFrame for easier analysis and comparison.\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame containing all benchmark results\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        return pd.DataFrame(self.results)\n",
    "\n",
    "    def run_scenarios(self, scenarios: List[Tuple[str, List[Tuple[str, Callable]]]], \n",
    "                    setup_method: Callable = None, \n",
    "                    cleanup_method: Callable = None):\n",
    "        \"\"\"\n",
    "        Run multiple benchmark scenarios and collect metrics\n",
    "        \n",
    "        Args:\n",
    "            scenarios: List of (scenario_name, [(operation_name, function)]) tuples\n",
    "            setup_method: Optional function to run before each scenario (not measured)\n",
    "            cleanup_method: Optional function to run after each scenario (not measured)\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: Results organized for comparison\n",
    "        \"\"\"\n",
    "        io_counters_start = psutil.disk_io_counters()\n",
    "        \n",
    "        # Run setup once if provided (not measured)\n",
    "        if setup_method:\n",
    "            setup_method()\n",
    "            \n",
    "        for scenario_name, operations in scenarios:\n",
    "            # Initialize metrics collection\n",
    "            start_time = time.time()\n",
    "            cpu_samples = []\n",
    "            memory_samples = []\n",
    "            durations = []\n",
    "            \n",
    "            # Execute all operations in the scenario\n",
    "            for op_name, func in operations:\n",
    "                # Sample CPU and memory\n",
    "                cpu_samples.append(self.process.cpu_percent())\n",
    "                memory_samples.append(self.process.memory_info().rss)\n",
    "                \n",
    "                # Execute function and measure time\n",
    "                op_start = time.time()\n",
    "                func()\n",
    "                op_duration = time.time() - op_start\n",
    "                durations.append(op_duration)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            end_time = time.time()\n",
    "            total_time = end_time - start_time\n",
    "            \n",
    "            # Resource usage\n",
    "            avg_cpu = statistics.mean(cpu_samples) if cpu_samples else 0\n",
    "            avg_memory = statistics.mean(memory_samples) / (1024 * 1024) if memory_samples else 0\n",
    "            \n",
    "            # Disk I/O \n",
    "            io_counters_end = psutil.disk_io_counters()\n",
    "            read_mb = (io_counters_end.read_bytes - io_counters_start.read_bytes) / (1024 * 1024)\n",
    "            write_mb = (io_counters_end.write_bytes - io_counters_start.write_bytes) / (1024 * 1024)\n",
    "            \n",
    "            # Performance metrics\n",
    "            avg_op_time = statistics.mean(durations) if durations else 0\n",
    "            throughput = len(operations) / total_time if total_time > 0 else 0\n",
    "            \n",
    "            # Save results for this scenario\n",
    "            scenario_result = {\n",
    "                'database': self.db_type,\n",
    "                'data_dir': self.data_dir,\n",
    "                'scenario': scenario_name,\n",
    "                'total_time': total_time,\n",
    "                'operations': len(operations),\n",
    "                'avg_operation_time': avg_op_time,\n",
    "                'throughput': throughput,\n",
    "                'cpu_avg': avg_cpu,\n",
    "                'memory_avg': avg_memory,\n",
    "                'disk_read_mb': read_mb,\n",
    "                'disk_write_mb': write_mb\n",
    "            }\n",
    "            self.results.append(scenario_result)\n",
    "            \n",
    "            # Print stats for this scenario\n",
    "            print(f\"--- {scenario_name} ({self.db_type}) ---\")\n",
    "            print(f\"Total time: {total_time:.4f} seconds\")\n",
    "            print(f\"Operations: {len(operations)}\")\n",
    "            print(f\"Avg operation time: {avg_op_time:.4f} seconds\")\n",
    "            print(f\"Throughput: {throughput:.2f} ops/sec\")\n",
    "            print(f\"CPU avg: {avg_cpu:.2f}%\")\n",
    "            print(f\"Memory avg: {avg_memory:.2f} MB\")\n",
    "            print(f\"Disk read: {read_mb:.2f} MB\")\n",
    "            print(f\"Disk write: {write_mb:.2f} MB\")\n",
    "            print()\n",
    "            \n",
    "            # Reset I/O counters for next scenario\n",
    "            io_counters_start = io_counters_end\n",
    "        \n",
    "        # Run cleanup if provided (not measured)\n",
    "        if cleanup_method:\n",
    "            cleanup_method()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bf1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT_TEACHER=\"INSERT Teacher ?\"\n",
    "INSERT_SUBJECT=\"INSERT Subject ?\"\n",
    "INSERT_CLASS=\"INSERT Class ?\"\n",
    "INSERT_STUDENT=\"INSERT Student ?\"\n",
    "INSERT_ENROLLMENT=\"INSERT Enrollment ?\"\n",
    "INSERT_GRADE=\"INSERT Grade ?\"\n",
    "INSERT_SCHEDULE=\"INSERT Schedule ?\"\n",
    "\n",
    "SELECT_STUDENT = \"SELECT student ?\"\n",
    "SELECT_CLASS = \"SELECT class ?\"\n",
    "SELECT_ALL_STUDENTS_TAUGHT_BY_TEACHER = \"SELECT all students that are taught by the teacher ?\"\n",
    "SELECT_ALL_SCHEDULES_FOR_A_SPECIFIC_STUDENT = \"SELECT all schedules for the student ?\"\n",
    "SELECT_ALL_GRADES_WITH_SUBJECT_DESCRIPTIONS_FOR_ALL_STUDENTS_IN_THE_CLASS = \"SELECT all grades with the subjects descriptions for all students in the class ?\"\n",
    "\n",
    "UPDATE_STUDENT_NAME = \"UPDATE Student ? Name\"\n",
    "UPDATE_ALL_GRADES_FOR_STUDENT = \"UPDATE all Grades for Student ?\"\n",
    "UPDATE_CLASS_NAME = \"UPDATE Class ? Name\"\n",
    "UPDATE_TEACHER_LAST_NAME = \"UPDATE Teacher ? Last Name\"\n",
    "UPDATE_SUBJECT_DESCRIPTION_FOR_ALL_SUBJECTS_THAT_STUDENTS_HAS_GRADES_FROM = \"UPDATE Subject ? Description for all subjects that students has grades from\"\n",
    "\n",
    "DELETE_STUDENT = \"DELETE Student ?\"\n",
    "DELETE_CLASS = \"DELETE Class ?\"\n",
    "DELETE_SUBJECTS_THAT_ARE_IN_THE_SCHEDULE_OF_THE_TEACHER = \"DELETE Subjects that are in the schedule of the teacher ?\"\n",
    "DELETE_TEACHER_WHO_TAUGHT_STUDENT = \"DELETE Teacher who taught student ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e08098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postgres_benchmark(data_dir, random_numbers_list) -> pd.DataFrame:\n",
    "    benchmark = SimpleBenchmark(\"postgres\", data_dir)\n",
    "    def setup_for_insert():\n",
    "        with open('schemas/postgres_schema.sql', 'r') as f:\n",
    "            sql_schema = f.read()\n",
    "\n",
    "        initialize_postgres_schema(postgres_client, sql_schema)\n",
    "        load_postgres_data(postgres_client, data_dir)\n",
    "\n",
    "    insert_scenarios = [\n",
    "        (\n",
    "            INSERT_TEACHER,\n",
    "            [\n",
    "                (INSERT_TEACHER + str(k), lambda k=k, v=v: postgres_operation(postgres_client, \n",
    "                    f\"INSERT INTO teachers (id, first_name, last_name, subject, hire_date, created_at) VALUES ({k}, '{v['first_name']}', '{v['last_name']}', '{v['subject']}', '{v['hire_date']}', '{v['created_at']}')\")) \n",
    "                for k, v in test_teachers.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_SUBJECT,\n",
    "            [\n",
    "                (INSERT_SUBJECT + str(k), lambda k=k, v=v: postgres_operation(postgres_client,\n",
    "                    f\"INSERT INTO subjects (id, name, description, created_at) VALUES ({k}, '{v['name']}', '{v['description']}', '{v['created_at']}')\"))\n",
    "                for k, v in test_subjects.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_CLASS,\n",
    "            [\n",
    "                (INSERT_CLASS + str(k), lambda k=k, v=v: postgres_operation(postgres_client,\n",
    "                    f\"INSERT INTO classes (id, name, teacher_id, created_at) VALUES ({k}, '{v['name']}', {v['teacher_id']}, '{v['created_at']}')\"))\n",
    "                for k, v in test_classes.items()\n",
    "            ]\n",
    "        ), \n",
    "        (\n",
    "            INSERT_STUDENT,\n",
    "            [\n",
    "                (INSERT_STUDENT + str(k), lambda k=k, v=v: postgres_operation(postgres_client,\n",
    "                    f\"INSERT INTO students (id, first_name, last_name, birth_date, created_at) VALUES ({k}, '{v['first_name']}', '{v['last_name']}', '{v['birth_date']}', '{v['created_at']}')\"))\n",
    "                for k, v in test_students.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_ENROLLMENT,\n",
    "            [\n",
    "                (INSERT_ENROLLMENT + str(k), lambda k=k, v=v: postgres_operation(postgres_client,\n",
    "                    f\"INSERT INTO enrollments (student_id, class_id, enrolled_at) VALUES ({k[0]}, {k[1]}, '{v['enrolled_at']}')\"))\n",
    "                for k, v in test_enrollments.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_GRADE,\n",
    "            [\n",
    "                (INSERT_GRADE + str(k), lambda k=k, v=v: postgres_operation(postgres_client,\n",
    "                    f\"INSERT INTO grades (id, student_id, subject_id, grade, created_at) VALUES ({k}, {v['student_id']}, {v['subject_id']}, {v['grade']}, '{v['created_at']}')\"))\n",
    "                for k, v in test_grades.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_SCHEDULE,\n",
    "            [\n",
    "                (INSERT_SCHEDULE + str(k), lambda k=k, v=v: postgres_operation(postgres_client,\n",
    "                    f\"INSERT INTO schedules (id, class_id, subject_id, day_of_week, time_start, time_end) VALUES ({k}, {v['class_id']}, {v['subject_id']}, '{v['day_of_week']}', '{v['time_start']}', '{v['time_end']}')\"))\n",
    "                for k, v in test_schedules.items()\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    select_scenarios = [\n",
    "        (\n",
    "            SELECT_STUDENT, [\n",
    "                (SELECT_STUDENT + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"SELECT * FROM students WHERE id = {k}\", fetch=True))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_CLASS, [\n",
    "                (SELECT_CLASS + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"SELECT * FROM classes WHERE id = {k}\", fetch=True))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_STUDENTS_TAUGHT_BY_TEACHER, [\n",
    "                (SELECT_ALL_STUDENTS_TAUGHT_BY_TEACHER + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"SELECT * FROM students s JOIN enrollments e ON s.id = e.student_id JOIN classes c ON e.class_id = c.id WHERE c.teacher_id = {k}\", fetch=True))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_SCHEDULES_FOR_A_SPECIFIC_STUDENT, [\n",
    "                (SELECT_ALL_SCHEDULES_FOR_A_SPECIFIC_STUDENT + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"SELECT * FROM schedules s JOIN classes c ON s.class_id = c.id JOIN enrollments e ON c.id = e.class_id WHERE e.student_id = {k}\", fetch=True))\n",
    "                for k in random_numbers_list\n",
    "            ] \n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_GRADES_WITH_SUBJECT_DESCRIPTIONS_FOR_ALL_STUDENTS_IN_THE_CLASS, [\n",
    "                (SELECT_ALL_GRADES_WITH_SUBJECT_DESCRIPTIONS_FOR_ALL_STUDENTS_IN_THE_CLASS + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"SELECT * FROM grades g JOIN subjects su ON g.subject_id = su.id JOIN students s ON g.student_id = s.id JOIN enrollments e ON s.id = e.student_id JOIN classes c ON e.class_id = c.id WHERE c.id = {k}\", fetch=True))\n",
    "                for k in random_numbers_list\n",
    "            ] \n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    update_scenarios = [\n",
    "        (\n",
    "            UPDATE_STUDENT_NAME, [\n",
    "                (UPDATE_STUDENT_NAME + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"UPDATE students SET last_name = 'UPDATED' WHERE id = {k}\"))\n",
    "                for k in random_numbers_list\n",
    "            ],\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_ALL_GRADES_FOR_STUDENT, [\n",
    "                (UPDATE_ALL_GRADES_FOR_STUDENT + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"UPDATE grades SET grade = 100 WHERE student_id = {k} AND subject_id = 10000011\"))\n",
    "                for k in random_numbers_list\n",
    "            ],\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_CLASS_NAME, [\n",
    "                (UPDATE_CLASS_NAME + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"UPDATE classes SET name = 'UPDATED' WHERE id = {k}\"))\n",
    "                for k in random_numbers_list\n",
    "            ],\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_TEACHER_LAST_NAME, [\n",
    "                (UPDATE_TEACHER_LAST_NAME + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"UPDATE teachers SET last_name = 'UPDATED' WHERE id = {k}\"))\n",
    "                for k in random_numbers_list\n",
    "            ],\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_SUBJECT_DESCRIPTION_FOR_ALL_SUBJECTS_THAT_STUDENTS_HAS_GRADES_FROM, [\n",
    "                (UPDATE_SUBJECT_DESCRIPTION_FOR_ALL_SUBJECTS_THAT_STUDENTS_HAS_GRADES_FROM + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"UPDATE subjects SET description = 'UPDATED' WHERE id IN (SELECT subject_id FROM grades WHERE student_id = {k})\"))\n",
    "                for k in random_numbers_list\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    delete_scenarios = [\n",
    "        (\n",
    "            DELETE_STUDENT, [\n",
    "                (DELETE_STUDENT + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"DELETE FROM students WHERE id = {k}\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_CLASS, [\n",
    "                (DELETE_CLASS + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"DELETE FROM classes WHERE id = {k}\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_SUBJECTS_THAT_ARE_IN_THE_SCHEDULE_OF_THE_TEACHER, [\n",
    "                (DELETE_SUBJECTS_THAT_ARE_IN_THE_SCHEDULE_OF_THE_TEACHER + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"DELETE FROM subjects WHERE id IN (SELECT subject_id FROM schedules WHERE class_id IN (SELECT id FROM classes WHERE teacher_id = {k}))\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_TEACHER_WHO_TAUGHT_STUDENT, [\n",
    "                (DELETE_TEACHER_WHO_TAUGHT_STUDENT + str(k), lambda k=k: postgres_operation(postgres_client,\n",
    "                    f\"DELETE FROM teachers WHERE id IN (SELECT teacher_id FROM classes WHERE id IN (SELECT class_id FROM enrollments WHERE student_id = {k}))\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    benchmark.run_scenarios(insert_scenarios, setup_method=setup_for_insert)\n",
    "    benchmark.run_scenarios(select_scenarios)\n",
    "    benchmark.run_scenarios(update_scenarios)\n",
    "    benchmark.run_scenarios(delete_scenarios)\n",
    "    return benchmark.get_results_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_date_format(date_string):\n",
    "    # from 2025-05-05T12:00:00Z to 2025-05-05 12:00:00\n",
    "    return date_string.replace(\"T\", \" \").replace(\"Z\", \"\")\n",
    "\n",
    "def mariadb_benchmark(data_dir, random_numbers_list) -> pd.DataFrame:\n",
    "    benchmark = SimpleBenchmark(\"mariadb\", data_dir)\n",
    "    def setup_for_insert():\n",
    "        with open('schemas/mariadb_schema.sql', 'r') as f:\n",
    "            sql_schema = f.read()\n",
    "\n",
    "        initialize_mariadb_schema(mariadb_client, sql_schema)\n",
    "        load_mariadb_data(mariadb_client, data_dir)\n",
    "\n",
    "    insert_scenarios = [\n",
    "        (\n",
    "            INSERT_TEACHER,\n",
    "            [\n",
    "                (INSERT_TEACHER + str(k), lambda k=k, v=v: mariadb_operation(mariadb_client, \n",
    "                    f\"INSERT INTO teachers (id, first_name, last_name, subject, hire_date, created_at) VALUES ({k}, '{v['first_name']}', '{v['last_name']}', '{v['subject']}', '{adjust_date_format(v['hire_date'])}', '{adjust_date_format(v['created_at'])}')\")) \n",
    "                for k, v in test_teachers.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_SUBJECT,\n",
    "            [\n",
    "                (INSERT_SUBJECT + str(k), lambda k=k, v=v: mariadb_operation(mariadb_client,\n",
    "                    f\"INSERT INTO subjects (id, name, description, created_at) VALUES ({k}, '{v['name']}', '{v['description']}', '{adjust_date_format(v['created_at'])}')\"))\n",
    "                for k, v in test_subjects.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_CLASS,\n",
    "            [\n",
    "                (INSERT_CLASS + str(k), lambda k=k, v=v: mariadb_operation(mariadb_client,\n",
    "                    f\"INSERT INTO classes (id, name, teacher_id, created_at) VALUES ({k}, '{v['name']}', {v['teacher_id']}, '{adjust_date_format(v['created_at'])}')\"))\n",
    "                for k, v in test_classes.items()\n",
    "            ]\n",
    "        ), \n",
    "        (\n",
    "            INSERT_STUDENT,\n",
    "            [\n",
    "                (INSERT_STUDENT + str(k), lambda k=k, v=v: mariadb_operation(mariadb_client,\n",
    "                    f\"INSERT INTO students (id, first_name, last_name, birth_date, created_at) VALUES ({k}, '{v['first_name']}', '{v['last_name']}', '{adjust_date_format(v['birth_date'])}', '{adjust_date_format(v['created_at'])}')\"))\n",
    "                for k, v in test_students.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_ENROLLMENT,\n",
    "            [\n",
    "                (INSERT_ENROLLMENT + str(k), lambda k=k, v=v: mariadb_operation(mariadb_client,\n",
    "                    f\"INSERT INTO enrollments (student_id, class_id, enrolled_at) VALUES ({k[0]}, {k[1]}, '{adjust_date_format(v['enrolled_at'])}')\"))\n",
    "                for k, v in test_enrollments.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_GRADE,\n",
    "            [\n",
    "                (INSERT_GRADE + str(k), lambda k=k, v=v: mariadb_operation(mariadb_client,\n",
    "                    f\"INSERT INTO grades (id, student_id, subject_id, grade, created_at) VALUES ({k}, {v['student_id']}, {v['subject_id']}, {v['grade']}, '{adjust_date_format(v['created_at'])}')\"))\n",
    "                for k, v in test_grades.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_SCHEDULE,\n",
    "            [\n",
    "                (INSERT_SCHEDULE + str(k), lambda k=k, v=v: mariadb_operation(mariadb_client,\n",
    "                    f\"INSERT INTO schedules (id, class_id, subject_id, day_of_week, time_start, time_end) VALUES ({k}, {v['class_id']}, {v['subject_id']}, '{v['day_of_week']}', '{v['time_start']}', '{v['time_end']}')\"))\n",
    "                for k, v in test_schedules.items()\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    select_scenarios = [\n",
    "        (\n",
    "            SELECT_STUDENT, [\n",
    "                (SELECT_STUDENT + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"SELECT * FROM students WHERE id = {k}\", fetch=True))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_CLASS, [\n",
    "                (SELECT_CLASS + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"SELECT * FROM classes WHERE id = {k}\", fetch=True))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_STUDENTS_TAUGHT_BY_TEACHER, [\n",
    "                (SELECT_ALL_STUDENTS_TAUGHT_BY_TEACHER + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"SELECT * FROM students s JOIN enrollments e ON s.id = e.student_id JOIN classes c ON e.class_id = c.id WHERE c.teacher_id = {k}\", fetch=True))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_SCHEDULES_FOR_A_SPECIFIC_STUDENT, [\n",
    "                (SELECT_ALL_SCHEDULES_FOR_A_SPECIFIC_STUDENT + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"SELECT * FROM schedules s JOIN classes c ON s.class_id = c.id JOIN enrollments e ON c.id = e.class_id WHERE e.student_id = {k}\", fetch=True))\n",
    "                for k in random_numbers_list\n",
    "            ] \n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_GRADES_WITH_SUBJECT_DESCRIPTIONS_FOR_ALL_STUDENTS_IN_THE_CLASS, [\n",
    "                (SELECT_ALL_GRADES_WITH_SUBJECT_DESCRIPTIONS_FOR_ALL_STUDENTS_IN_THE_CLASS + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"SELECT * FROM grades g JOIN subjects su ON g.subject_id = su.id JOIN students s ON g.student_id = s.id JOIN enrollments e ON s.id = e.student_id JOIN classes c ON e.class_id = c.id WHERE c.id = {k}\", fetch=True))\n",
    "                for k in random_numbers_list\n",
    "            ] \n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    update_scenarios = [\n",
    "        (\n",
    "            UPDATE_STUDENT_NAME, [\n",
    "                (UPDATE_STUDENT_NAME + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"UPDATE students SET last_name = 'UPDATED' WHERE id = {k}\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_ALL_GRADES_FOR_STUDENT, [\n",
    "                (UPDATE_ALL_GRADES_FOR_STUDENT + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"UPDATE grades SET grade = 100 WHERE student_id = {k} AND subject_id = 10000011\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_CLASS_NAME, [\n",
    "                (UPDATE_CLASS_NAME + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"UPDATE classes SET name = 'UPDATED' WHERE id = {k}\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_TEACHER_LAST_NAME, [\n",
    "                (UPDATE_TEACHER_LAST_NAME + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"UPDATE teachers SET last_name = 'UPDATED' WHERE id = {k}\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_SUBJECT_DESCRIPTION_FOR_ALL_SUBJECTS_THAT_STUDENTS_HAS_GRADES_FROM, [\n",
    "                (UPDATE_SUBJECT_DESCRIPTION_FOR_ALL_SUBJECTS_THAT_STUDENTS_HAS_GRADES_FROM + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"UPDATE subjects SET description = 'UPDATED' WHERE id IN (SELECT subject_id FROM grades WHERE student_id = {k})\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    delete_scenarios = [\n",
    "        (\n",
    "            DELETE_STUDENT, [\n",
    "                (DELETE_STUDENT + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"DELETE FROM students WHERE id = {k}\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_CLASS, [\n",
    "                (DELETE_CLASS + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"DELETE FROM classes WHERE id = {k}\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_SUBJECTS_THAT_ARE_IN_THE_SCHEDULE_OF_THE_TEACHER, [\n",
    "                (DELETE_SUBJECTS_THAT_ARE_IN_THE_SCHEDULE_OF_THE_TEACHER + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"DELETE FROM subjects WHERE id IN (SELECT subject_id FROM schedules WHERE class_id IN (SELECT id FROM classes WHERE teacher_id = {k}))\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_TEACHER_WHO_TAUGHT_STUDENT, [\n",
    "                (DELETE_TEACHER_WHO_TAUGHT_STUDENT + str(k), lambda k=k: mariadb_operation(mariadb_client,\n",
    "                    f\"DELETE FROM teachers WHERE id IN (SELECT teacher_id FROM classes WHERE id IN (SELECT class_id FROM enrollments WHERE student_id = {k}))\"))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    benchmark.run_scenarios(insert_scenarios, setup_method=setup_for_insert)\n",
    "    benchmark.run_scenarios(select_scenarios)\n",
    "    benchmark.run_scenarios(update_scenarios)\n",
    "    benchmark.run_scenarios(delete_scenarios)\n",
    "    return benchmark.get_results_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e57b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mongo_benchmark(data_dir, random_numbers_list) -> pd.DataFrame:\n",
    "    benchmark = SimpleBenchmark(\"mongodb\", data_dir)\n",
    "    \n",
    "    def setup_for_insert():\n",
    "        # Initialize MongoDB schema - create collections and indexes\n",
    "        initialize_mongo_schema(mongo_client)\n",
    "        # Load data from CSV files\n",
    "        load_mongo_data(mongo_client, data_dir)\n",
    "    \n",
    "    insert_scenarios = [\n",
    "        (\n",
    "            INSERT_TEACHER,\n",
    "            [\n",
    "                (INSERT_TEACHER + str(k), lambda k=k, v=v: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'teachers', 'insert',\n",
    "                    data={\n",
    "                        \"_id\": k,\n",
    "                        \"first_name\": v['first_name'],\n",
    "                        \"last_name\": v['last_name'],\n",
    "                        \"subject\": v['subject'],\n",
    "                        \"hire_date\": v['hire_date'],\n",
    "                        \"created_at\": v['created_at']\n",
    "                    }\n",
    "                )) for k, v in test_teachers.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_SUBJECT,\n",
    "            [\n",
    "                (INSERT_SUBJECT + str(k), lambda k=k, v=v: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'subjects', 'insert',\n",
    "                    data={\n",
    "                        \"_id\": k,\n",
    "                        \"name\": v['name'],\n",
    "                        \"description\": v['description'],\n",
    "                        \"created_at\": v['created_at']\n",
    "                    }\n",
    "                )) for k, v in test_subjects.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_CLASS,\n",
    "            [\n",
    "                (INSERT_CLASS + str(k), lambda k=k, v=v: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'classes', 'insert',\n",
    "                    data={\n",
    "                        \"_id\": k,\n",
    "                        \"name\": v['name'],\n",
    "                        \"teacher_id\": v['teacher_id'],\n",
    "                        \"created_at\": v['created_at']\n",
    "                    }\n",
    "                )) for k, v in test_classes.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_STUDENT,\n",
    "            [\n",
    "                (INSERT_STUDENT + str(k), lambda k=k, v=v: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'students', 'insert',\n",
    "                    data={\n",
    "                        \"_id\": k,\n",
    "                        \"first_name\": v['first_name'],\n",
    "                        \"last_name\": v['last_name'],\n",
    "                        \"birth_date\": v['birth_date'],\n",
    "                        \"created_at\": v['created_at'],\n",
    "                        \"enrollments\": [],\n",
    "                        \"grades\": []\n",
    "                    }\n",
    "                )) for k, v in test_students.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_ENROLLMENT,\n",
    "            [\n",
    "                (INSERT_ENROLLMENT + str(k), lambda k=k, v=v: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'students', 'update',\n",
    "                    query={\"_id\": k[0]},\n",
    "                    data={\"$push\": {\"enrollments\": {\n",
    "                        \"class_id\": k[1],\n",
    "                        \"enrolled_at\": v['enrolled_at']\n",
    "                    }}}\n",
    "                )) for k, v in test_enrollments.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_GRADE,\n",
    "            [\n",
    "                (INSERT_GRADE + str(k), lambda k=k, v=v: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'students', 'update',\n",
    "                    query={\"_id\": v['student_id']},\n",
    "                    data={\"$push\": {\"grades\": {\n",
    "                        \"grade_id\": k,\n",
    "                        \"subject_id\": v['subject_id'],\n",
    "                        \"grade\": v['grade'],\n",
    "                        \"created_at\": v['created_at']\n",
    "                    }}}\n",
    "                )) for k, v in test_grades.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_SCHEDULE,\n",
    "            [\n",
    "                (INSERT_SCHEDULE + str(k), lambda k=k, v=v: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'classes', 'update',\n",
    "                    query={\"_id\": v['class_id']},\n",
    "                    data={\"$push\": {\"schedule\": {\n",
    "                        \"schedule_id\": k,\n",
    "                        \"subject_id\": v['subject_id'],\n",
    "                        \"day_of_week\": v['day_of_week'],\n",
    "                        \"time_start\": v['time_start'],\n",
    "                        \"time_end\": v['time_end']\n",
    "                    }}}\n",
    "                )) for k, v in test_schedules.items()\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    select_scenarios = [\n",
    "        (\n",
    "            SELECT_STUDENT, [\n",
    "                (SELECT_STUDENT + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'students', 'find',\n",
    "                    query={\"_id\": k},\n",
    "                    fetch=True\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_CLASS, [\n",
    "                (SELECT_CLASS + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'classes', 'find',\n",
    "                    query={\"_id\": k},\n",
    "                    fetch=True\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_STUDENTS_TAUGHT_BY_TEACHER, [\n",
    "                (SELECT_ALL_STUDENTS_TAUGHT_BY_TEACHER + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'students', 'find',\n",
    "                    query={\"enrollments.class_id\": {\"$in\": \n",
    "                            [doc[\"_id\"] for doc in mongo_client['benchmark']['classes'].find({\"teacher_id\": k}, {\"_id\": 1})]}},\n",
    "                    fetch=True\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_SCHEDULES_FOR_A_SPECIFIC_STUDENT, [\n",
    "                (SELECT_ALL_SCHEDULES_FOR_A_SPECIFIC_STUDENT + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'classes', 'find',\n",
    "                    query={\n",
    "                        \"_id\": {\"$in\": list(\n",
    "                            map(lambda x: x[\"class_id\"], \n",
    "                                mongo_client['benchmark']['students'].find_one({\"_id\": k}, {\"enrollments\": 1})[\"enrollments\"]\n",
    "                            )\n",
    "                        )}\n",
    "                    },\n",
    "                    options={\"projection\": {\"schedule\": 1, \"name\": 1}},\n",
    "                    fetch=True\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_GRADES_WITH_SUBJECT_DESCRIPTIONS_FOR_ALL_STUDENTS_IN_THE_CLASS, [\n",
    "                (SELECT_ALL_GRADES_WITH_SUBJECT_DESCRIPTIONS_FOR_ALL_STUDENTS_IN_THE_CLASS + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'students', 'find',\n",
    "                    query={\"enrollments.class_id\": k},\n",
    "                    options={\n",
    "                        \"projection\": {\n",
    "                            \"first_name\": 1, \n",
    "                            \"last_name\": 1, \n",
    "                            \"grades\": 1\n",
    "                        }\n",
    "                    },\n",
    "                    fetch=True\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    update_scenarios = [\n",
    "        (\n",
    "            UPDATE_STUDENT_NAME, [\n",
    "                (UPDATE_STUDENT_NAME + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'students', 'update',\n",
    "                    query={\"_id\": k},\n",
    "                    data={\"$set\": {\"last_name\": \"UPDATED\"}}\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_ALL_GRADES_FOR_STUDENT, [\n",
    "                (UPDATE_ALL_GRADES_FOR_STUDENT + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'students', 'update',\n",
    "                    query={\n",
    "                        \"_id\": k,\n",
    "                        \"grades.subject_id\": 10000011\n",
    "                    },\n",
    "                    data={\"$set\": {\"grades.$.grade\": 100}}\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_CLASS_NAME, [\n",
    "                (UPDATE_CLASS_NAME + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'classes', 'update',\n",
    "                    query={\"_id\": k},\n",
    "                    data={\"$set\": {\"name\": \"UPDATED\"}}\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_TEACHER_LAST_NAME, [\n",
    "                (UPDATE_TEACHER_LAST_NAME + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'teachers', 'update',\n",
    "                    query={\"_id\": k},\n",
    "                    data={\"$set\": {\"last_name\": \"UPDATED\"}}\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_SUBJECT_DESCRIPTION_FOR_ALL_SUBJECTS_THAT_STUDENTS_HAS_GRADES_FROM, [\n",
    "                (UPDATE_SUBJECT_DESCRIPTION_FOR_ALL_SUBJECTS_THAT_STUDENTS_HAS_GRADES_FROM + str(k), lambda k=k: \n",
    "                    # First get all subject IDs that the student has grades for\n",
    "                    [mongo_operation(\n",
    "                        mongo_client, 'benchmark', 'subjects', 'update',\n",
    "                        query={\"_id\": subject_id},\n",
    "                        data={\"$set\": {\"description\": \"UPDATED\"}}\n",
    "                    ) for subject_id in list(map(\n",
    "                        lambda x: x[\"subject_id\"], \n",
    "                        mongo_client['benchmark']['students'].find_one({\"_id\": k}, {\"grades.subject_id\": 1})[\"grades\"]\n",
    "                    ))]\n",
    "                ) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    delete_scenarios = [\n",
    "        (\n",
    "            DELETE_STUDENT, [\n",
    "                (DELETE_STUDENT + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'students', 'delete',\n",
    "                    query={\"_id\": k}\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_CLASS, [\n",
    "                (DELETE_CLASS + str(k), lambda k=k: mongo_operation(\n",
    "                    mongo_client, 'benchmark', 'classes', 'delete',\n",
    "                    query={\"_id\": k}\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_SUBJECTS_THAT_ARE_IN_THE_SCHEDULE_OF_THE_TEACHER, [\n",
    "                (DELETE_SUBJECTS_THAT_ARE_IN_THE_SCHEDULE_OF_THE_TEACHER + str(k), lambda k=k: \n",
    "                    # Find classes taught by teacher, then get all subject IDs from those classes' schedules\n",
    "                    [mongo_operation(\n",
    "                        mongo_client, 'benchmark', 'subjects', 'delete',\n",
    "                        query={\"_id\": {\"$in\": list(set([\n",
    "                            schedule[\"subject_id\"] for class_doc in \n",
    "                            mongo_client['benchmark']['classes'].find({\"teacher_id\": k}) \n",
    "                            for schedule in class_doc.get(\"schedule\", [])\n",
    "                        ]))}}\n",
    "                    )]\n",
    "                ) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_TEACHER_WHO_TAUGHT_STUDENT, [\n",
    "                (DELETE_TEACHER_WHO_TAUGHT_STUDENT + str(k), lambda k=k:\n",
    "                    # Find student's enrolled class IDs, then find teachers of those classes\n",
    "                    (lambda student_doc: \n",
    "                        [mongo_operation(\n",
    "                            mongo_client, 'benchmark', 'teachers', 'delete',\n",
    "                            query={\"_id\": {\"$in\": list(set([\n",
    "                                class_doc[\"teacher_id\"] for class_id in \n",
    "                                [enroll[\"class_id\"] for enroll in student_doc.get(\"enrollments\", [])]\n",
    "                                for class_doc in mongo_client['benchmark']['classes'].find({\"_id\": class_id})\n",
    "                            ]))}} if student_doc else {}\n",
    "                        )]\n",
    "                    )(mongo_client['benchmark']['students'].find_one({\"_id\": k}, {\"enrollments\": 1}))\n",
    "                ) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    benchmark.run_scenarios(insert_scenarios, setup_method=setup_for_insert)\n",
    "    benchmark.run_scenarios(select_scenarios)\n",
    "    benchmark.run_scenarios(update_scenarios)\n",
    "    benchmark.run_scenarios(delete_scenarios)\n",
    "    \n",
    "    return benchmark.get_results_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e9666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cassandra_benchmark(data_dir, random_numbers_list) -> pd.DataFrame:\n",
    "    benchmark = SimpleBenchmark(\"cassandra\", data_dir)\n",
    "    \n",
    "    def setup_for_insert():\n",
    "        # Initialize Cassandra schema\n",
    "        initialize_cassandra_schema(cassandra_session)\n",
    "        # Load data from CSV files\n",
    "        load_cassandra_data(cassandra_session, data_dir)\n",
    "\n",
    "    def to_datetime(date_string):\n",
    "        \"\"\"Convert ISO 8601 datetime string to Python datetime object\"\"\"\n",
    "        from datetime import datetime\n",
    "        if not date_string or not isinstance(date_string, str):\n",
    "            return date_string\n",
    "        return datetime.fromisoformat(date_string.replace('Z', '+00:00'))\n",
    "    \n",
    "    # INSERT scenarios\n",
    "    insert_scenarios = [\n",
    "        (\n",
    "            INSERT_TEACHER,\n",
    "            [\n",
    "                (INSERT_TEACHER + str(k), lambda k=k, v=v: cassandra_operation(\n",
    "                    cassandra_session, \n",
    "                    \"INSERT INTO teachers (id, first_name, last_name) VALUES (?, ?, ?)\",\n",
    "                    params=[k, v['first_name'], v['last_name']]\n",
    "                )) for k, v in test_teachers.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_SUBJECT,\n",
    "            [\n",
    "                (INSERT_SUBJECT + str(k), lambda k=k, v=v: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"INSERT INTO subjects (id, name, description) VALUES (?, ?, ?)\",\n",
    "                    params=[k, v['name'], v['description']]\n",
    "                )) for k, v in test_subjects.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_CLASS,\n",
    "            [\n",
    "                (INSERT_CLASS + str(k), lambda k=k, v=v: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"INSERT INTO classes (id, name, teacher_id) VALUES (?, ?, ?)\",\n",
    "                    params=[k, v['name'], v['teacher_id']]\n",
    "                )) for k, v in test_classes.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_STUDENT,\n",
    "            [\n",
    "                (INSERT_STUDENT + str(k), lambda k=k, v=v: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"INSERT INTO students (id, first_name, last_name, birth_date) VALUES (?, ?, ?, ?)\",\n",
    "                    params=[k, v['first_name'], v['last_name'], v['birth_date']]\n",
    "                )) for k, v in test_students.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_ENROLLMENT,\n",
    "            [\n",
    "                (INSERT_ENROLLMENT + str(k), lambda k=k, v=v: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"INSERT INTO enrollments (student_id, class_id, enrolled_at) VALUES (?, ?, ?)\",\n",
    "                    params=[k[0], k[1], to_datetime(v['enrolled_at'])]\n",
    "                )) for k, v in test_enrollments.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_GRADE,\n",
    "            [\n",
    "                (INSERT_GRADE + str(k), lambda k=k, v=v: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"INSERT INTO grades (id, student_id, subject_id, grade, created_at) VALUES (?, ?, ?, ?, ?)\",\n",
    "                    params=[k, v['student_id'], v['subject_id'], v['grade'], to_datetime(v['created_at'])]\n",
    "                )) for k, v in test_grades.items()\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            INSERT_SCHEDULE,\n",
    "            [\n",
    "                (INSERT_SCHEDULE + str(k), lambda k=k, v=v: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"INSERT INTO schedules (id, class_id, subject_id, day_of_week, time_start, time_end) VALUES (?, ?, ?, ?, ?, ?)\",\n",
    "                    params=[k, v['class_id'], v['subject_id'], v['day_of_week'], v['time_start'], v['time_end']]\n",
    "                )) for k, v in test_schedules.items()\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # SELECT scenarios\n",
    "    select_scenarios = [\n",
    "        (\n",
    "            SELECT_STUDENT, [\n",
    "                (SELECT_STUDENT + str(k), lambda k=k: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"SELECT * FROM students WHERE id = ?\",\n",
    "                    params=[k],\n",
    "                    fetch=True\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_CLASS, [\n",
    "                (SELECT_CLASS + str(k), lambda k=k: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"SELECT * FROM classes WHERE id = ?\",\n",
    "                    params=[k],\n",
    "                    fetch=True\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_STUDENTS_TAUGHT_BY_TEACHER, [\n",
    "                (SELECT_ALL_STUDENTS_TAUGHT_BY_TEACHER + str(k), lambda k=k: cassandra_operation(\n",
    "                    # Using denormalized table that links teachers to students\n",
    "                    cassandra_session,\n",
    "                    \"SELECT * FROM teacher_students WHERE teacher_id = ?\",\n",
    "                    params=[k],\n",
    "                    fetch=True\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_SCHEDULES_FOR_A_SPECIFIC_STUDENT, [\n",
    "                (SELECT_ALL_SCHEDULES_FOR_A_SPECIFIC_STUDENT + str(k), lambda k=k: cassandra_operation(\n",
    "                    # Using denormalized table for student schedules\n",
    "                    cassandra_session,\n",
    "                    \"SELECT * FROM student_schedules WHERE student_id = ?\",\n",
    "                    params=[k],\n",
    "                    fetch=True\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            SELECT_ALL_GRADES_WITH_SUBJECT_DESCRIPTIONS_FOR_ALL_STUDENTS_IN_THE_CLASS, [\n",
    "                (SELECT_ALL_GRADES_WITH_SUBJECT_DESCRIPTIONS_FOR_ALL_STUDENTS_IN_THE_CLASS + str(k), lambda k=k: cassandra_operation(\n",
    "                    # Using denormalized table for grades with descriptions by class\n",
    "                    cassandra_session,\n",
    "                    \"SELECT * FROM student_grades_with_descriptions_and_classes WHERE class_id = ?\",\n",
    "                    params=[k],\n",
    "                    fetch=True\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # UPDATE scenarios\n",
    "    update_scenarios = [\n",
    "        (\n",
    "            UPDATE_STUDENT_NAME, [\n",
    "                (UPDATE_STUDENT_NAME + str(k), lambda k=k: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"UPDATE students SET last_name = 'UPDATED' WHERE id = ?\",\n",
    "                    params=[k]\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_ALL_GRADES_FOR_STUDENT, [\n",
    "                (UPDATE_ALL_GRADES_FOR_STUDENT + str(k), lambda k=k: update_all_grades_for_student(cassandra_session, k))\n",
    "                for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_CLASS_NAME, [\n",
    "                (UPDATE_CLASS_NAME + str(k), lambda k=k: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"UPDATE classes SET name = 'UPDATED' WHERE id = ?\",\n",
    "                    params=[k]\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_TEACHER_LAST_NAME, [\n",
    "                (UPDATE_TEACHER_LAST_NAME + str(k), lambda k=k: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"UPDATE teachers SET last_name = 'UPDATED' WHERE id = ?\",\n",
    "                    params=[k]\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            UPDATE_SUBJECT_DESCRIPTION_FOR_ALL_SUBJECTS_THAT_STUDENTS_HAS_GRADES_FROM, [\n",
    "                (UPDATE_SUBJECT_DESCRIPTION_FOR_ALL_SUBJECTS_THAT_STUDENTS_HAS_GRADES_FROM + str(k), \n",
    "                lambda k=k: update_subjects_for_student_grades(cassandra_session, k)\n",
    "                ) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # DELETE scenarios\n",
    "    delete_scenarios = [\n",
    "        (\n",
    "            DELETE_STUDENT, [\n",
    "                (DELETE_STUDENT + str(k), lambda k=k: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"DELETE FROM students WHERE id = ?\",\n",
    "                    params=[k]\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_CLASS, [\n",
    "                (DELETE_CLASS + str(k), lambda k=k: cassandra_operation(\n",
    "                    cassandra_session,\n",
    "                    \"DELETE FROM classes WHERE id = ?\",\n",
    "                    params=[k]\n",
    "                )) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_SUBJECTS_THAT_ARE_IN_THE_SCHEDULE_OF_THE_TEACHER, [\n",
    "                (DELETE_SUBJECTS_THAT_ARE_IN_THE_SCHEDULE_OF_THE_TEACHER + str(k), \n",
    "                lambda k=k: delete_subjects_for_teacher(cassandra_session, k)\n",
    "                ) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            DELETE_TEACHER_WHO_TAUGHT_STUDENT, [\n",
    "                (DELETE_TEACHER_WHO_TAUGHT_STUDENT + str(k), \n",
    "                lambda k=k: delete_teachers_for_student(cassandra_session, k)\n",
    "                ) for k in random_numbers_list\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # Run all benchmark scenarios\n",
    "    benchmark.run_scenarios(insert_scenarios, setup_method=setup_for_insert)\n",
    "    benchmark.run_scenarios(select_scenarios)\n",
    "    benchmark.run_scenarios(update_scenarios)\n",
    "    benchmark.run_scenarios(delete_scenarios)\n",
    "    \n",
    "    return benchmark.get_results_df()\n",
    "\n",
    "\n",
    "def update_all_grades_for_student(session, student_id):\n",
    "    \"\"\"Update grades for a specific student and subject\"\"\"\n",
    "    try:\n",
    "        # First find the relevant grade IDs\n",
    "        select_stmt = session.prepare(\n",
    "            \"SELECT id FROM grades WHERE student_id = ? AND subject_id = 10000011 ALLOW FILTERING\"\n",
    "        )\n",
    "        grade_rows = session.execute(select_stmt, [student_id])\n",
    "        \n",
    "        # Update each grade individually\n",
    "        update_stmt = session.prepare(\n",
    "            \"UPDATE grades SET grade = 100 WHERE id = ?\"\n",
    "        )\n",
    "        for grade_row in grade_rows:\n",
    "            session.execute(update_stmt, [grade_row.id])\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to update grades: {e}\")\n",
    "        return False\n",
    "\n",
    "def update_subjects_for_student_grades(session, student_id):\n",
    "    \"\"\"Update descriptions for subjects that a student has grades from\"\"\"\n",
    "    try:\n",
    "        # First get all grades for the student\n",
    "        select_stmt = session.prepare(\n",
    "            \"SELECT subject_id FROM grades WHERE student_id = ? ALLOW FILTERING\"\n",
    "        )\n",
    "        rows = session.execute(select_stmt, [student_id])\n",
    "        \n",
    "        # Extract unique subject IDs (in Python, not in CQL)\n",
    "        subject_ids = set()\n",
    "        for row in rows:\n",
    "            subject_ids.add(row.subject_id)\n",
    "        \n",
    "        # Update each subject\n",
    "        update_stmt = session.prepare(\n",
    "            \"UPDATE subjects SET description = 'UPDATED' WHERE id = ?\"\n",
    "        )\n",
    "        for subject_id in subject_ids:\n",
    "            session.execute(update_stmt, [subject_id])\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to update subject descriptions: {e}\")\n",
    "        return False\n",
    "\n",
    "def delete_subjects_for_teacher(session, teacher_id):\n",
    "    \"\"\"Delete subjects in the schedule of a teacher\"\"\"\n",
    "    try:\n",
    "        # Find classes for this teacher\n",
    "        class_stmt = session.prepare(\n",
    "            \"SELECT id FROM classes WHERE teacher_id = ? ALLOW FILTERING\"\n",
    "        )\n",
    "        class_rows = session.execute(class_stmt, [teacher_id])\n",
    "        \n",
    "        # Collect subject IDs from schedules for these classes\n",
    "        subject_ids = set()\n",
    "        schedule_stmt = session.prepare(\n",
    "            \"SELECT subject_id FROM schedules WHERE class_id = ? ALLOW FILTERING\"\n",
    "        )\n",
    "        \n",
    "        for class_row in class_rows:\n",
    "            schedule_rows = session.execute(schedule_stmt, [class_row.id])\n",
    "            for schedule_row in schedule_rows:\n",
    "                subject_ids.add(schedule_row.subject_id)\n",
    "        \n",
    "        # Delete each subject\n",
    "        delete_stmt = session.prepare(\n",
    "            \"DELETE FROM subjects WHERE id = ?\"\n",
    "        )\n",
    "        for subject_id in subject_ids:\n",
    "            session.execute(delete_stmt, [subject_id])\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to delete subjects for teacher: {e}\")\n",
    "        return False\n",
    "\n",
    "def delete_teachers_for_student(session, student_id):\n",
    "    \"\"\"Delete teachers who taught a student\"\"\"\n",
    "    try:\n",
    "        # First find class IDs for this student\n",
    "        select_enrollments_stmt = session.prepare(\n",
    "            \"SELECT class_id FROM enrollments WHERE student_id = ?\"\n",
    "        )\n",
    "        enrollment_rows = session.execute(select_enrollments_stmt, [student_id])\n",
    "        \n",
    "        # Find teacher IDs for these classes\n",
    "        teacher_ids = set()\n",
    "        select_class_stmt = session.prepare(\n",
    "            \"SELECT teacher_id FROM classes WHERE id = ?\"\n",
    "        )\n",
    "        \n",
    "        for enrollment_row in enrollment_rows:\n",
    "            class_rows = session.execute(select_class_stmt, [enrollment_row.class_id])\n",
    "            for class_row in class_rows:\n",
    "                teacher_ids.add(class_row.teacher_id)\n",
    "        \n",
    "        # Delete each teacher\n",
    "        delete_stmt = session.prepare(\n",
    "            \"DELETE FROM teachers WHERE id = ?\"\n",
    "        )\n",
    "        for teacher_id in teacher_ids:\n",
    "            session.execute(delete_stmt, [teacher_id])\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to delete teachers for student: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_database_performance_grid(\n",
    "    df,\n",
    "    metric='total_time',\n",
    "    data_dir=None,\n",
    "    figsize=(18, 15),\n",
    "    title=None,\n",
    "    sort_by=None,\n",
    "    log_scale=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a 2x2 grid of performance comparison plots for different databases,\n",
    "    showing INSERT, SELECT, UPDATE, and DELETE operations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The merged DataFrame containing all benchmark results\n",
    "    metric : str, default='total_time'\n",
    "        The metric to plot. Must be one of:\n",
    "        'total_time', 'operations', 'avg_operation_time', 'throughput',\n",
    "        'cpu_avg', 'memory_avg', 'disk_read_mb', 'disk_write_mb'\n",
    "    data_dir : str, optional\n",
    "        Filter by specific data directory\n",
    "    figsize : tuple, default=(18, 15)\n",
    "        Figure size as (width, height)\n",
    "    title : str, optional\n",
    "        Custom title for the overall plot\n",
    "    sort_by : str, optional\n",
    "        Sort scenarios by: 'name', 'value', or None for default ordering\n",
    "    log_scale : bool, default=False\n",
    "        Use logarithmic scale for the metric axis\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fig, axes: matplotlib figure and 2x2 array of axes objects\n",
    "    \"\"\"\n",
    "    # Validate metric\n",
    "    valid_metrics = ['total_time', 'operations', 'avg_operation_time', 'throughput',\n",
    "                    'cpu_avg', 'memory_avg', 'disk_read_mb', 'disk_write_mb']\n",
    "    \n",
    "    if metric not in valid_metrics:\n",
    "        raise ValueError(f\"Invalid metric: {metric}. Must be one of {valid_metrics}\")\n",
    "    \n",
    "    # Clone dataframe to avoid modifying the original\n",
    "    plot_df = df.copy()\n",
    "    \n",
    "    # Apply data directory filter if specified\n",
    "    if data_dir:\n",
    "        plot_df = plot_df[plot_df['data_dir'] == data_dir]\n",
    "    \n",
    "    # Create 2x2 grid of subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Set Seaborn style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # The four CRUD operations to display\n",
    "    operations = ['INSERT', 'SELECT', 'UPDATE', 'DELETE']\n",
    "    \n",
    "    # Plot each operation in its own subplot\n",
    "    for i, operation in enumerate(operations):\n",
    "        # Filter data for this operation\n",
    "        op_df = plot_df[plot_df['scenario'].str.contains(operation, case=False)]\n",
    "        \n",
    "        if op_df.empty:\n",
    "            axes[i].text(0.5, 0.5, f\"No data for {operation} operations\", \n",
    "                         ha='center', va='center', fontsize=14)\n",
    "            continue\n",
    "            \n",
    "        # Get unique databases and scenarios for this operation\n",
    "        databases = op_df['database'].unique()\n",
    "        scenarios = op_df['scenario'].unique()\n",
    "        \n",
    "        # Sort scenarios if requested\n",
    "        if sort_by == 'name':\n",
    "            scenarios = sorted(scenarios)\n",
    "        \n",
    "        # Define color palette for this subplot\n",
    "        palette = sns.color_palette(\"husl\", len(scenarios))\n",
    "        \n",
    "        # Calculate bar width based on number of scenarios\n",
    "        bar_width = 0.8 / len(scenarios)\n",
    "        \n",
    "        # Create bars for each scenario\n",
    "        for j, scenario in enumerate(scenarios):\n",
    "            # Get data for this scenario\n",
    "            scenario_data = op_df[op_df['scenario'] == scenario]\n",
    "            \n",
    "            # Calculate x positions for this scenario\n",
    "            x = np.arange(len(databases))\n",
    "            offset = (j - len(scenarios)/2 + 0.5) * bar_width\n",
    "            \n",
    "            # Get values for each database for this metric and scenario\n",
    "            values = []\n",
    "            for db in databases:\n",
    "                val = scenario_data[scenario_data['database'] == db][metric].values\n",
    "                values.append(val[0] if len(val) > 0 else np.nan)\n",
    "            \n",
    "            # Plot bars\n",
    "            axes[i].bar(x + offset, values, width=bar_width, \n",
    "                        label=scenario.replace(operation, '').strip(), \n",
    "                        color=palette[j])\n",
    "        \n",
    "        # Set logarithmic scale if requested\n",
    "        if log_scale and all(v > 0 for v in op_df[metric].values):\n",
    "            axes[i].set_yscale('log')\n",
    "        \n",
    "        # Customize subplot\n",
    "        axes[i].set_title(f\"{operation} Operations\", fontsize=14)\n",
    "        axes[i].set_xlabel('Database', fontsize=12)\n",
    "        axes[i].set_ylabel(metric.replace('_', ' ').title(), fontsize=12)\n",
    "        axes[i].set_xticks(np.arange(len(databases)))\n",
    "        axes[i].set_xticklabels(databases, rotation=45, ha='right')\n",
    "        \n",
    "        # Add legend for this subplot if there are multiple scenarios\n",
    "        if len(scenarios) > 1:\n",
    "            axes[i].legend(fontsize=9, loc='best')\n",
    "    \n",
    "    # Add overall title if provided\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=18, y=0.98)\n",
    "    else:\n",
    "        fig.suptitle(f\"{metric.replace('_', ' ').title()} by Database and Operation Type\", \n",
    "                     fontsize=18, y=0.98)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ba94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "def run_benchmark_for_databases(scale):\n",
    "\n",
    "    data_path = './data/scale_' + str(scale)\n",
    "    generate_files(output_dir=data_path, scale=scale, batch_size=5000)\n",
    "    rand_list = sample(range(1, scale+1), 10)\n",
    "\n",
    "    postgres_results_df = postgres_benchmark(data_path, rand_list)\n",
    "    mariadb_results_df = mariadb_benchmark(data_path, rand_list)\n",
    "    mongo_results_df = mongo_benchmark(data_path, rand_list)\n",
    "    cassandra_results_df = cassandra_benchmark(data_path, rand_list)\n",
    "    merged_df = pd.concat([postgres_results_df, mariadb_results_df, mongo_results_df, cassandra_results_df], ignore_index=True)\n",
    "\n",
    "    fig, axes = plot_database_performance_grid(\n",
    "        merged_df, \n",
    "        metric='total_time',\n",
    "        log_scale=False,\n",
    "        data_dir=data_path,\n",
    "        sort_by='name'\n",
    "    )\n",
    "    fig.savefig(f\"{data_path}/total_time_performance.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "    fig, axes = plot_database_performance_grid(\n",
    "        merged_df, \n",
    "        metric='avg_operation_time',\n",
    "        log_scale=False,\n",
    "        data_dir=data_path,\n",
    "        sort_by='name'\n",
    "    )\n",
    "    fig.savefig(f\"{data_path}/avg_operation_time_performance.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "    fig, axes = plot_database_performance_grid(\n",
    "        merged_df, \n",
    "        metric='memory_avg',\n",
    "        log_scale=True,\n",
    "        data_dir=data_path,\n",
    "        sort_by='name'\n",
    "    )\n",
    "    fig.savefig(f\"{data_path}/memory_avg_performance.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "    fig, axes = plot_database_performance_grid(\n",
    "        merged_df, \n",
    "        metric='cpu_avg',\n",
    "        log_scale=False,\n",
    "        sort_by='name',\n",
    "        data_dir=data_path,\n",
    "    )\n",
    "    fig.savefig(f\"{data_path}/cpu_avg_performance.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "    fig, axes = plot_database_performance_grid(\n",
    "        merged_df, \n",
    "        metric='throughput',\n",
    "        log_scale=False,\n",
    "        sort_by='name',\n",
    "        data_dir=data_path,\n",
    "    )\n",
    "    fig.savefig(f\"{data_path}/throughput_performance.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6559ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_benchmark_for_databases(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db-benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 9
}
